import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('TkAgg')  # ä¿ç•™æ‚¨çš„TkAggè®¾ç½®
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, List, Optional, Callable
import warnings
import os
from typing import Dict
from scipy.stats import pearsonr
from sklearn.linear_model import Lasso
import joblib # å¯¼å…¥ joblib ç”¨äºä¿å­˜æ¨¡å‹
from sklearn.preprocessing import StandardScaler
# é…ç½®ä¸­æ–‡æ˜¾ç¤ºå’Œè­¦å‘Šè¿‡æ»¤
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial']
matplotlib.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


class CS500FactorAnalyzer:

    def __init__(self, data_folder: str):
        self.data_folder = Path(data_folder)
        self.all_data = {}
        self.factor_results = {}
        self.synthetic_factors = {}

    def parse_dirty_wide_table(self, raw_data: pd.DataFrame, sheet_name: str = None) -> pd.DataFrame:
        try:
            data = raw_data.copy()
            # 1. è®¾ç½®åˆ—åä¸ºè‚¡ç¥¨ä»£ç ï¼ˆç¬¬1è¡Œï¼Œç´¢å¼• 0ï¼‰
            data.columns = data.iloc[0].values
            # 2. åˆ é™¤å‰ä¸¤è¡Œï¼ˆä»£ç è¡Œå’Œåç§°è¡Œï¼‰
            clean_data = data.iloc[2:].copy()
            # 3. è®¾ç½®æ—¶é—´ç´¢å¼•ï¼ˆç¬¬ä¸€åˆ—ï¼‰
            time_col_name = clean_data.columns[0]
            clean_data = clean_data.set_index(time_col_name)
            cleaned_index = [val if not isinstance(val, tuple) else pd.NaT for val in clean_data.index]
            clean_data.index = pd.Index(cleaned_index)
            # 4. è§£ææ—¶é—´ç´¢å¼•å¹¶è½¬ä¸ºæ•°å€¼
            clean_data.index = pd.to_datetime(clean_data.index)
            # ç¡®ä¿æ•°æ®åˆ—æ˜¯æ•°å€¼ç±»å‹ï¼Œéæ•°å€¼è½¬ä¸º NaN
            clean_data = clean_data.apply(pd.to_numeric, errors='coerce')

            # 5. æ¸…ç†å’Œç»Ÿä¸€å‘½å (å…ˆåˆ é™¤å…¨ä¸ºç©ºçš„åˆ—ï¼Œå†è¿›è¡Œå¡«å……)
            clean_data = clean_data.dropna(axis=1, how='all')

            # # ==================== 0å€¼å’Œç¼ºå¤±å€¼å¤„ç†é€»è¾‘ (æ–°å¢/ä¿®æ”¹) ====================
            # target_sheets = ['ROE', 'è‡ªç”±ç°é‡‘æµ', 'EPS', 'EBITDA']
            clean_data = clean_data.replace(0, np.nan)

            # 2. å¯¹æ‰€æœ‰ NaN (åŒ…æ‹¬åŸæ¥çš„ NaN å’Œç”± 0 æ›¿æ¢æ¥çš„ NaN) æ‰§è¡Œå‘å‰å¡«å…… (ffill)
            clean_data = clean_data.fillna(method='ffill')
            # ==================== 0å€¼å’Œç¼ºå¤±å€¼å¤„ç†é€»è¾‘ (ç»“æŸ) ====================

            # 6. æ¸…ç†å’Œç»Ÿä¸€å‘½å (ä¸åŸæœ‰é€»è¾‘ä¸€è‡´)
            clean_data.columns.name = 'code'
            clean_data.index.name = 'date'

            # if sheet_name:
            #     print(sheet_name)
            #     print(
            #         f"âœ… è§£æå®Œæˆ: {clean_data.shape}, æ—¶é—´èŒƒå›´: {clean_data.index.min()} åˆ° {clean_data.index.max()}")

            return clean_data

        except Exception as e:
            print(f"âŒ è§£æ {sheet_name} å¤±è´¥: {e}")
            raise

    def load_all_periods(self):
        """åŠ è½½æ‰€æœ‰æ—¶é—´ç‚¹çš„æ•°æ®"""

        # 1. æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶ (.xlsx å’Œ .xls)ï¼Œå¹¶æŒ‰åç§°æ’åº
        excel_files = sorted(
            list(self.data_folder.glob("ä¸­è¯500_*.xlsx")) +
            list(self.data_folder.glob("ä¸­è¯500_*.xls"))
        )

        if not excel_files:
            print(
                f"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ° Excel æ–‡ä»¶ã€‚è¯·æ£€æŸ¥è·¯å¾„ï¼š{self.data_folder} ä¸‹æ˜¯å¦å­˜åœ¨å‘½åä¸º 'ä¸­è¯500_*.xlsx' æˆ– 'ä¸­è¯500_*.xls' çš„æ–‡ä»¶ã€‚")
            return

        print(f"æ‰¾åˆ° {len(excel_files)} ä¸ªæ•°æ®æ–‡ä»¶")

        for file in excel_files:
            # ã€ä¿®æ”¹ 1ï¼šæå–å‘¨æœŸåç§°ï¼Œå¹¶å»æ‰ "ä¸­è¯500_" å‰ç¼€ã€‘
            period_name = file.stem.replace("ä¸­è¯500_", "")
            print(f"\nğŸ“ åŠ è½½: {period_name}")

            try:
                xl_file = pd.ExcelFile(file)
                period_data = {}

                for sheet_name in xl_file.sheet_names:
                    # Sheet1 é€šå¸¸æ˜¯è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                    if sheet_name == 'Sheet1':
                        stock_info = pd.read_excel(file, sheet_name=sheet_name)
                        period_data['stock_info'] = stock_info
                    else:
                        sheet_data = pd.read_excel(file, sheet_name=sheet_name, header=None)
                        try:
                            parsed_data = self.parse_dirty_wide_table(sheet_data, sheet_name)

                            if parsed_data.empty:
                                continue

                            period_data[sheet_name] = parsed_data

                        except Exception:
                            continue

                self.all_data[period_name] = period_data

                # æ‰“å°åŠ è½½æˆåŠŸçš„å› å­é”®
                loaded_keys = [k for k in period_data.keys() if k != 'stock_info']

                # ã€ä¿®æ”¹ 3ï¼šåœ¨åŠ è½½å®Œæˆçš„è¾“å‡ºä¸­ï¼Œä¹Ÿä½¿ç”¨å»æ‰å‰ç¼€çš„ period_nameã€‘
                print(f"    âœ… {period_name} æ–‡ä»¶åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(loaded_keys)} ä¸ªå› å­æ•°æ®é¡¹ã€‚Keys: {loaded_keys}")


            except Exception as e:
                print(f"âŒ åŠ è½½æ–‡ä»¶ {file.name} å¤±è´¥: {e}")

        # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
        if self.all_data:
            self._display_data_overview()
        else:
            print("\nâš ï¸  æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®")

    def _display_data_overview(self):
        print(f"\n{'=' * 60}")
        print("æ•°æ®åŠ è½½æ¦‚è§ˆ")
        print(f"{'=' * 60}")

        for period_name, period_data in self.all_data.items():
            print(f"\nğŸ“… æ—¶é—´æ®µ: {period_name}")
    def calculate_synthetic_factor(self, factor_name: str, calculation_func: Callable):
        print(f"\nğŸ”§ è®¡ç®—åˆæˆå› å­: {factor_name}")
        self.synthetic_factors[factor_name] = {}
        success_count = 0
        for period_name, period_data in self.all_data.items():
            try:
                # ä¼ å…¥ period_data (åŒ…å«æ‰€æœ‰æ—¶é—´åºåˆ—å®½è¡¨)
                factor_data = calculation_func(period_data)

                # æ£€æŸ¥è¿”å›ç»“æœæ˜¯å¦ä¸ºæ¯æ—¥æ—¶é—´åºåˆ—å®½è¡¨
                if not factor_data.empty and factor_data.index.name == 'date' and factor_data.columns.name == 'code':
                    self.synthetic_factors[factor_name][period_name] = factor_data
                    success_count += 1
                    print(
                        f"   âœ… {period_name}: è®¡ç®—æˆåŠŸ, æ¯æ—¥æˆªé¢: {len(factor_data)}, è‚¡ç¥¨æ•°: {len(factor_data.columns)}")
                else:
                    print(f"   âš ï¸  {period_name}: æ— æœ‰æ•ˆæ•°æ®æˆ–æ•°æ®æ ¼å¼é”™è¯¯")
            except Exception as e:
                print(f"   âŒ {period_name}: è®¡ç®—å¤±è´¥ - {e}")

        print(f"ğŸ“ˆ {factor_name} è®¡ç®—å®Œæˆ: {success_count}/{len(self.all_data)} ä¸ªæ—¶é—´æ®µ")
    def calculate_alpha1(self, period_data: Dict) -> pd.DataFrame:
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. ç¡®ä¿æ•°æ®å¯¹é½
        common_stocks = close_df.columns.intersection(volume_df.columns)
        close_df = close_df[common_stocks]
        volume_df = volume_df[common_stocks]
        close_rank_cs = close_df.rank(axis=1, pct=True)  # æ¯å¤©åœ¨æ‰€æœ‰è‚¡ç¥¨ä¸­æ’å
        volume_rank_cs = volume_df.rank(axis=1, pct=True)

        # 1b. è®¡ç®—è¿™ä¸¤ç»„æ’ååºåˆ—åœ¨è¿‡å»10å¤©çš„**æ—¶é—´åºåˆ—**ç›¸å…³æ€§ (rolling(10).corr())
        # è¿™æ ·è®¡ç®—çš„æ˜¯**æ–¯çš®å°”æ›¼ç­‰çº§ç›¸å…³ç³»æ•°** (Spearman's rank correlation coefficient)
        # å¯¹æ¯åªè‚¡ç¥¨ï¼Œè®¡ç®—å…¶è¿‡å»10å¤©çš„ (close_rank_cs, volume_rank_cs) çš„ç›¸å…³æ€§ã€‚
        corr_term_raw = close_rank_cs.rolling(window=10).corr(volume_rank_cs)

        # --- Step 2: rank(correlation_term) * rank(delta_term) ---

        # 2a. å¯¹ç›¸å…³æ€§é¡¹è¿›è¡Œ**æˆªé¢**æ’å: rank(corr_term_raw)
        rank_corr_term = corr_term_raw.rank(axis=1, pct=True)

        # 2b. æ»šåŠ¨è®¡ç®—ä»·æ ¼å˜åŒ–é¡¹: delta(close, 5)
        delta_term_raw = close_df.diff(5)

        # 2c. å¯¹ä»·æ ¼å˜åŒ–é¡¹è¿›è¡Œ**æˆªé¢**æ’å: rank(delta(close, 5))
        rank_delta_term = delta_term_raw.rank(axis=1, pct=True)

        # 2d. ç»„åˆ: rank(correlation(...)) * rank(delta(...))
        raw_factor_df = rank_corr_term * rank_delta_term

        # --- Step 3: æœ€ç»ˆå› å­å€¼ (åŸå§‹å› å­å€¼æ˜¯æ¯æ—¥æˆªé¢å€¼) ---
        # å¯¹æœ€ç»ˆç»“æœè¿›è¡Œæˆªé¢æ’åï¼Œè¿™æ˜¯é€šå¸¸çš„åšæ³•ï¼Œä»¥ç¡®ä¿å› å­å€¼åˆ†å¸ƒç»Ÿä¸€
        alpha1_df = raw_factor_df.rank(axis=1, pct=True, method='average')

        # æ¸…ç†å’Œç»Ÿä¸€å‘½å
        alpha1_df.columns.name = 'code'
        alpha1_df.index.name = 'date'

        # åˆ é™¤æ‰€æœ‰è‚¡ç¥¨éƒ½æ˜¯ NaN çš„æ—¥æœŸ
        return alpha1_df.dropna(how='all')

    def calculate_alpha2(self, period_data: Dict) -> pd.DataFrame:
        """
        Alpha#2 (æ¯æ—¥æ»šåŠ¨): rank(delta(close, 5)) * rank(delta(volume, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        common_stocks = close_df.columns.intersection(volume_df.columns)
        close_df = close_df[common_stocks]
        volume_df = volume_df[common_stocks]

        # 1. 5æ—¥ä»·æ ¼å˜åŒ–: delta(close, 5)
        delta_close = close_df.diff(5)
        # 2. 5æ—¥æˆäº¤é‡å˜åŒ–: delta(volume, 5)
        delta_volume = volume_df.diff(5)

        # 3. æˆªé¢æ’å (Cross-sectional Rank): è¿™æ˜¯å…³é”®ï¼
        # rank(delta(close, 5))
        ranked_delta_close = delta_close.rank(axis=1, pct=True, method='average')
        # rank(delta(volume, 5))
        ranked_delta_volume = delta_volume.rank(axis=1, pct=True, method='average')

        # 4. æœ€ç»ˆå› å­å€¼: ä¸¤ä¸ªæ’åå€¼çš„ä¹˜ç§¯
        alpha2_df = ranked_delta_close * ranked_delta_volume

        alpha2_df.columns.name = 'code'
        alpha2_df.index.name = 'date'

        # åˆ é™¤æ‰€æœ‰è‚¡ç¥¨éƒ½æ˜¯ NaN çš„æ—¥æœŸ
        return alpha2_df.dropna(how='all')

    def calculate_alpha3(self, period_data: Dict) -> pd.DataFrame:
        """
        Alpha#3 (æ¯æ—¥æ»šåŠ¨): rank(stddev(close, 10)) * rank(delta(volume, 5))
        è¿™é‡Œæˆ‘ä»¬è®¡ç®—ï¼šrank(stddev(close, 10)) * rank(delta(volume, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        common_stocks = close_df.columns.intersection(volume_df.columns)
        close_df = close_df[common_stocks]
        volume_df = volume_df[common_stocks]

        # 1. æ»šåŠ¨è®¡ç®—10æ—¥æ³¢åŠ¨ç‡: stddev(close, 10)
        volatility_term = close_df.rolling(window=10).std()

        # 2. æ»šåŠ¨è®¡ç®—5æ—¥æˆäº¤é‡å˜åŒ–: delta(volume, 5)
        delta_volume_term = volume_df.diff(5)

        # 3. æˆªé¢æ’å: åˆ†åˆ«å¯¹ä¸¤ä¸ªé¡¹è¿›è¡Œæ¯æ—¥æˆªé¢æ’å
        # rank(stddev(close, 10))
        ranked_volatility = volatility_term.rank(axis=1, pct=True, method='average')

        # rank(delta(volume, 5))
        ranked_delta_volume = delta_volume_term.rank(axis=1, pct=True, method='average')

        # 4. æœ€ç»ˆå› å­å€¼: ä¸¤ä¸ªæ’åå€¼çš„ä¹˜ç§¯
        alpha3_df = ranked_volatility * ranked_delta_volume

        alpha3_df.columns.name = 'code'
        alpha3_df.index.name = 'date'

        return alpha3_df.dropna(how='all')

    def calculate_ROC6(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: ROC6 (6å‘¨æœŸä»·æ ¼å˜åŒ–ç‡)
        å…¬å¼: (æ”¶ç›˜ä»· / Nå‘¨æœŸå‰æ”¶ç›˜ä»· - 1) * 100
        """
        if 'æ”¶ç›˜ä»·' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']

        # è®¡ç®— N=6 å‘¨æœŸå‰çš„æ”¶ç›˜ä»·
        close_lagged = close_df.shift(6)

        # è®¡ç®—ROC6
        ROC6_df = ((close_df / close_lagged) - 1) * 100

        # æˆªé¢æ’å (å¯é€‰ï¼Œä½†é€šå¸¸å› å­éƒ½éœ€è¦æ’åæˆ–æ ‡å‡†åŒ–)
        factor_df = ROC6_df.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')
    def calculate_BIAS60(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: BIAS60 (60å‘¨æœŸä»·æ ¼ä¹–ç¦»ç‡)
        å…¬å¼: (æ”¶ç›˜ä»· - 60å‘¨æœŸå‡ä»·) / 60å‘¨æœŸå‡ä»· * 100
        """
        if 'æ”¶ç›˜ä»·' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']

        # è®¡ç®—60å‘¨æœŸç®€å•ç§»åŠ¨å¹³å‡çº¿ (Simple Moving Average, SMA)
        MA60 = close_df.rolling(window=60).mean()

        # è®¡ç®—BIAS60
        BIAS60_df = ((close_df - MA60) / MA60) * 100

        # æˆªé¢æ’å
        factor_df = BIAS60_df.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')
    def calculate_CCI20(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: CCI20 (20å‘¨æœŸå•†å“é€šé“æŒ‡æ•°)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æ—¥æœ€é«˜ä»·' not in period_data or 'æ—¥æœ€ä½ä»·' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·ã€æœ€é«˜ä»·æˆ–æœ€ä½ä»·æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        high_df = period_data['æ—¥æœ€é«˜ä»·']
        low_df = period_data['æ—¥æœ€ä½ä»·']
        N = 20

        # 1. è®¡ç®— Typical Price (TP)
        TP_df = (high_df + low_df + close_df) / 3

        # 2. è®¡ç®— TP çš„ N å‘¨æœŸ SMA (SMATP)
        SMATP_df = TP_df.rolling(window=N).mean()

        # 3. è®¡ç®— N å‘¨æœŸå¹³å‡ç»å¯¹åå·® (Mean Deviation)
        # MeanDeviation = SMA(|TP - SMATP|, N)
        MD_df = (TP_df - SMATP_df).abs().rolling(window=N).mean()

        # 4. è®¡ç®— CCI
        # é¿å…é™¤ä»¥é›¶
        MD_df_safe = MD_df.replace(0, np.nan)
        CCI20_df = (TP_df - SMATP_df) / (0.015 * MD_df_safe)

        # æˆªé¢æ’å
        factor_df = CCI20_df.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')
    def calculate_WVAD6(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: WVAD (6å‘¨æœŸåŠ æƒæˆäº¤é‡å˜å¼‚åº¦ - å¹³æ»‘å½¢å¼)
        å…¬å¼: SMA( ( (Close - Open) / (High - Low) ) * Volume , 6 )
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'å¼€ç›˜ä»·' not in period_data or \
                'æ—¥æœ€é«˜ä»·' not in period_data or 'æ—¥æœ€ä½ä»·' not in period_data or 'æˆäº¤é‡' not in period_data:
            raise ValueError("ç¼ºå°‘ä»·æ ¼æˆ–æˆäº¤é‡æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        open_df = period_data['å¼€ç›˜ä»·']
        high_df = period_data['æ—¥æœ€é«˜ä»·']
        low_df = period_data['æ—¥æœ€ä½ä»·']
        volume_df = period_data['æˆäº¤é‡']
        N = 6

        # 1. è®¡ç®—æ ¸å¿ƒæ¯”ç‡: (Close - Open) / (High - Low)
        # é¿å…é™¤ä»¥é›¶: å½“ High=Low æ—¶ï¼Œè¯¥æ¯”ç‡ä¸º NaN (æˆ–è®¾ä¸º0)
        price_range = high_df - low_df
        # ä½¿ç”¨ np.divide å®‰å…¨åœ°æ‰§è¡Œé™¤æ³•ï¼Œå¹¶ç”¨ where é¿å…é™¤é›¶
        ratio_df = np.divide(close_df - open_df, price_range,
                             out=np.zeros_like(price_range, dtype=float),
                             where=price_range != 0)

        # 2. è®¡ç®—åŠ æƒæˆäº¤é‡: Ratio * Volume
        weighted_volume = ratio_df * volume_df

        # 3. è®¡ç®— N=6 å‘¨æœŸç§»åŠ¨å¹³å‡ (SMA)
        WVAD_df = weighted_volume.rolling(window=N).mean()

        # æˆªé¢æ’å
        factor_df = WVAD_df.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_EP_Factor(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: EP (ç›ˆåˆ©æ”¶ç›Šç‡)
        å…¬å¼: 1 / PEï¼Œç„¶åè¿›è¡Œæˆªé¢æ’åã€‚
        """
        if 'PE' not in period_data:
            raise ValueError("ç¼ºå°‘PEæ•°æ®")

        PE_df = period_data['PE']

        # é¿å…é™¤é›¶å’Œæç«¯å€¼ï¼šPE > 0 æ‰æœ‰æ„ä¹‰
        EP_df = 1.0 / PE_df.mask(PE_df <= 0)

        # æˆªé¢æ’å (rank(axis=1))
        factor_df = EP_df.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_ROE_Factor(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: ROE (å‡€èµ„äº§æ”¶ç›Šç‡)
        å…¬å¼: ROEï¼Œç„¶åè¿›è¡Œæˆªé¢æ’åã€‚
        """
        if 'ROE' not in period_data:
            raise ValueError("ç¼ºå°‘ROEæ•°æ®")

        ROE_df = period_data['ROE']

        # å¯¹ROEè¿›è¡Œæˆªé¢æ’å
        factor_df = ROE_df.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_EPS_Growth_Factor(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: EPS_Growth (250æ—¥EPSå¢é•¿ç‡)
        å…¬å¼: (EPS / 250å‘¨æœŸå‰EPS) - 1ï¼Œç„¶åè¿›è¡Œæˆªé¢æ’åã€‚
        """
        if 'EPS' not in period_data:
            raise ValueError("ç¼ºå°‘EPSæ•°æ®")

        EPS_df = period_data['EPS']

        # EPS è¿‡å» 250 ä¸ªå‘¨æœŸï¼ˆçº¦ä¸€å¹´ï¼‰å‰çš„æ•°å€¼
        EPS_lagged = EPS_df.shift(30)

        # è®¡ç®—å¢é•¿ç‡
        growth_df = (EPS_df / EPS_lagged) - 1

        # æˆªé¢æ’å
        factor_df = growth_df.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Turnover20_Factor(self, period_data: Dict) -> pd.DataFrame:
        """
        å› å­: Turnover20 (20æ—¥å¹³å‡æ¢æ‰‹ç‡)
        å…¬å¼: 20æ—¥æ¢æ‰‹ç‡çš„ç®€å•ç§»åŠ¨å¹³å‡ (SMA)ï¼Œç„¶åè¿›è¡Œæˆªé¢æ’åã€‚
        """
        if 'æ¢æ‰‹ç‡' not in period_data:
            raise ValueError("ç¼ºå°‘æ¢æ‰‹ç‡æ•°æ®")

        turnover_df = period_data['æ¢æ‰‹ç‡']

        # è®¡ç®—20æ—¥ç®€å•ç§»åŠ¨å¹³å‡
        SMA_turnover = turnover_df.rolling(window=20).mean()

        # æˆªé¢æ’å
        factor_df = SMA_turnover.rank(axis=1, pct=True)

        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_momentum_value_composite(self, period_data: Dict) -> pd.DataFrame:
        """
        åŠ¨é‡-ä»·å€¼å¤åˆå› å­
        å…¬å¼: rank(ROC20) * rank(1/PE)
        ç»“åˆä¸­æœŸåŠ¨é‡ä¸ä»·å€¼ä½ä¼°
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'PE' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–PEæ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        pe_df = period_data['PE']

        # 20æ—¥åŠ¨é‡
        roc20 = (close_df / close_df.shift(20) - 1)

        # ä»·å€¼å› å­ (ç›ˆåˆ©æ”¶ç›Šç‡)
        ep = 1.0 / pe_df.mask(pe_df <= 0)

        # å¤åˆå› å­
        composite = roc20.rank(axis=1, pct=True) * ep.rank(axis=1, pct=True)

        factor_df = composite.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_vol_adjusted_value(self, period_data: Dict) -> pd.DataFrame:
        """
        æ³¢åŠ¨ç‡è°ƒæ•´ä»·å€¼å› å­
        å…¬å¼: rank(EP) / rank(æ³¢åŠ¨ç‡)
        åœ¨ä»·å€¼å› å­ä¸Šè€ƒè™‘é£é™©è°ƒæ•´
        """
        if 'PE' not in period_data or 'æ”¶ç›˜ä»·' not in period_data:
            raise ValueError("ç¼ºå°‘PEæˆ–æ”¶ç›˜ä»·æ•°æ®")

        pe_df = period_data['PE']
        close_df = period_data['æ”¶ç›˜ä»·']

        # ç›ˆåˆ©æ”¶ç›Šç‡
        ep = 1.0 / pe_df.mask(pe_df <= 0)

        # 20æ—¥æ³¢åŠ¨ç‡
        volatility = close_df.pct_change().rolling(20).std()

        # æ³¢åŠ¨ç‡è°ƒæ•´ä»·å€¼
        vol_adjusted_ep = ep.rank(axis=1, pct=True) / (volatility.rank(axis=1, pct=True) + 1e-6)

        factor_df = vol_adjusted_ep.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_volume_price_divergence(self, period_data: Dict) -> pd.DataFrame:
        """
        é‡ä»·èƒŒç¦»å› å­
        å…¬å¼: rank(ä»·æ ¼åŠ¨é‡) - rank(æˆäº¤é‡åŠ¨é‡)
        æ•æ‰é‡ä»·èƒŒç¦»çš„æŠ€æœ¯ä¿¡å·
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 5æ—¥ä»·æ ¼åŠ¨é‡
        price_momentum = close_df.pct_change(5)

        # 5æ—¥æˆäº¤é‡åŠ¨é‡
        volume_momentum = volume_df.pct_change(5)

        # é‡ä»·èƒŒç¦»
        divergence = price_momentum.rank(axis=1, pct=True) - volume_momentum.rank(axis=1, pct=True)

        factor_df = divergence.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_profitability_growth(self, period_data: Dict) -> pd.DataFrame:
        """
        ç›ˆåˆ©èƒ½åŠ›å¢é•¿å› å­
        å…¬å¼: rank(ROEå˜åŒ–ç‡) * rank(EBITDAå¢é•¿ç‡)
        æ•æ‰ç›ˆåˆ©èƒ½åŠ›çš„æ”¹å–„è¶‹åŠ¿
        """
        if 'ROE' not in period_data or 'EBITDA' not in period_data:
            raise ValueError("ç¼ºå°‘ROEæˆ–EBITDAæ•°æ®")

        roe_df = period_data['ROE']
        ebitda_df = period_data['EBITDA']

        # ROE 60æ—¥å˜åŒ–ç‡
        roe_growth = (roe_df / roe_df.shift(60) - 1)

        # EBITDA 60æ—¥å¢é•¿ç‡
        ebitda_growth = (ebitda_df / ebitda_df.shift(60) - 1)

        # å¤åˆå¢é•¿å› å­
        growth_factor = roe_growth.rank(axis=1, pct=True) * ebitda_growth.rank(axis=1, pct=True)

        factor_df = growth_factor.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

        # --------------------------------------------------------
        # >>>>>> æ–°å¢å› å­è®¡ç®—æ–¹æ³• (A. ä»·é‡è¶‹åŠ¿ä¸åŠ¨é‡å› å­) <<<<<<
        # --------------------------------------------------------
    def calculate_Momentum_Ranking_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼åŠ¨é‡å› å­ I: rank(delta(close, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        delta_term = close_df.diff(5)
        factor_df = delta_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')



    def calculate_Price_Rate_of_Change_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼å˜åŠ¨é€Ÿç‡å› å­ I: (close - close.shift(12)) / close.shift(12)
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        roc_term = (close_df - close_df.shift(12)) / close_df.shift(12)
        factor_df = roc_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Cumulative_Price_Change_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ç´¯ç§¯ä»·æ ¼å˜åŒ–å› å­ I: rank(sum(delta(close, 1), 30))
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        delta_1 = close_df.diff(1)
        # 30æ—¥ç´¯è®¡å˜åŒ– (å³è¿‘30æ—¥æ¶¨è·Œå¹…)
        sum_delta = delta_1.rolling(window=30).sum()
        factor_df = sum_delta.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Multi_period_Momentum_Overlay_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¤šæœŸåŠ¨é‡å åŠ å› å­ I: rank(delta(close, 5)) * rank(delta(close, 10))
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        rank_delta_5 = close_df.diff(5).rank(axis=1, pct=True)
        rank_delta_10 = close_df.diff(10).rank(axis=1, pct=True)
        raw_factor_df = rank_delta_5 * rank_delta_10
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_High_Low_Price_Momentum_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        é«˜ä½ä»·åŠ¨é‡å› å­ I: rank(delta(close, 5)) * rank(delta(high, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æ—¥æœ€é«˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æœ€é«˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        high_df = period_data['æ—¥æœ€é«˜ä»·']
        rank_delta_close_5 = close_df.diff(5).rank(axis=1, pct=True)
        rank_delta_high_5 = high_df.diff(5).rank(axis=1, pct=True)
        raw_factor_df = rank_delta_close_5 * rank_delta_high_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Long_term_Price_Level_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        é•¿æœŸä»·æ ¼æ°´å¹³å› å­ I: rank(sum(close, 60) / 60)
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ma_60 = close_df.rolling(window=60).mean()
        factor_df = ma_60.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Momentum_Indicator_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        åŠ¨é‡æŒ‡æ ‡å› å­ I: close - close.shift(5)
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        momentum_term = close_df - close_df.shift(5)
        factor_df = momentum_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # æ³¨ï¼šPrice Trend Evaluation Factor I, Aroon Up/Down, Price-Volume Synchronization Factor I, Price-Volume Intensity Factor I, Market Trend Correlation Factor I æ¶‰åŠå¸‚åœºæŒ‡æ•°æˆ–å¤æ‚æŠ€æœ¯æŒ‡æ ‡ï¼Œè‹¥æ— å¸‚åœºæŒ‡æ•°æ•°æ®ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—ã€‚è¿™é‡Œå®ç°**ä¸ä¾èµ–**å¸‚åœºæŒ‡æ•°çš„å› å­ã€‚

    # --- æˆäº¤é‡ç¡®è®¤åŠ¨é‡å› å­ (å®ç°å¯è¡Œçš„éƒ¨åˆ†) ---
    def calculate_Price_Volume_Synchronization_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·é‡åŒæ­¥æ€§å› å­ I: rank(delta(close, 5)) * rank(delta(volume, 5))
        (ä¸ Alpha#2 ç±»ä¼¼ï¼Œä½†Alpha#2æ˜¯ä¸¤ä¸ªæ’åä¹˜ç§¯åå†æ’åï¼Œè¿™é‡Œç›´æ¥å®ç°å…¬å¼)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']
        rank_delta_close_5 = close_df.diff(5).rank(axis=1, pct=True)
        rank_delta_volume_5 = volume_df.diff(5).rank(axis=1, pct=True)
        raw_factor_df = rank_delta_close_5 * rank_delta_volume_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Volume_Intensity_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·é‡å¼ºåº¦å› å­ I: rank(correlation(rank(close), rank(volume), 10)) * rank(delta(close, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. æ¯æ—¥æˆªé¢æ’å
        rank_close = close_df.rank(axis=1, pct=True)
        rank_volume = volume_df.rank(axis=1, pct=True)

        # 2. è®¡ç®— 10 æ—¥æ»šåŠ¨ç›¸å…³æ€§ (æ—¶é—´åºåˆ—ç›¸å…³æ€§)
        # æ³¨æ„ï¼šè¿™é‡Œè®¡ç®—çš„æ˜¯æ¯æ—¥æˆªé¢æ’ååçš„**æ—¶é—´åºåˆ—**ç›¸å…³æ€§
        corr_term_raw = rank_close.rolling(window=10).corr(rank_volume)

        # 3. å¯¹ç›¸å…³æ€§é¡¹è¿›è¡Œæˆªé¢æ’å
        rank_corr_term = corr_term_raw.rank(axis=1, pct=True)

        # 4. rank(delta(close, 5))
        rank_delta_close_5 = close_df.diff(5).rank(axis=1, pct=True)

        # 5. å¤åˆ
        raw_factor_df = rank_corr_term * rank_delta_close_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Volume_Gain_Synergy_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·é‡æ¶¨å¹…ååŒå› å­ I: rank(delta(close, 5)) * rank(delta(volume, 5))
        (ä¸ Price-Volume Synchronization Factor I ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        return self.calculate_Price_Volume_Synchronization_Factor_I(period_data)

    def calculate_Relative_Strength_Volume_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ç›¸å¯¹å¼ºåº¦æˆäº¤é‡å› å­ I: rank((close - delay(close, 5))) * rank(delta(volume, 10))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. close - delay(close, 5) å³ close_df.diff(5)
        rank_delta_close_5 = close_df.diff(5).rank(axis=1, pct=True)

        # 2. rank(delta(volume, 10))
        rank_delta_volume_10 = volume_df.diff(10).rank(axis=1, pct=True)

        raw_factor_df = rank_delta_close_5 * rank_delta_volume_10
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Volume_Intensity_Factor(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·é‡å¼ºåº¦å› å­: rank(correlation(rank(close), rank(volume), 20)) * rank(delta(close, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. æ¯æ—¥æˆªé¢æ’å
        rank_close = close_df.rank(axis=1, pct=True)
        rank_volume = volume_df.rank(axis=1, pct=True)

        # 2. è®¡ç®— 20 æ—¥æ»šåŠ¨ç›¸å…³æ€§
        corr_term_raw = rank_close.rolling(window=20).corr(rank_volume)

        # 3. å¯¹ç›¸å…³æ€§é¡¹è¿›è¡Œæˆªé¢æ’å
        rank_corr_term = corr_term_raw.rank(axis=1, pct=True)

        # 4. rank(delta(close, 5))
        rank_delta_close_5 = close_df.diff(5).rank(axis=1, pct=True)

        # 5. å¤åˆ
        raw_factor_df = rank_corr_term * rank_delta_close_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Multi_period_Price_Volume_Momentum_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¤šæœŸä»·é‡åŠ¨é‡å› å­ I: rank(delta(close, 5)) * rank(delta(volume, 10))
        (ä¸ Relative_Strength_Volume_Factor_I ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        return self.calculate_Relative_Strength_Volume_Factor_I(period_data)

    def calculate_Price_Volume_Absolute_Synchronization_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·é‡ç»å¯¹åŒæ­¥å› å­ I: rank(abs(delta(close, 5))) * rank(abs(delta(volume, 5)))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        rank_abs_delta_close_5 = close_df.diff(5).abs().rank(axis=1, pct=True)
        rank_abs_delta_volume_5 = volume_df.diff(5).abs().rank(axis=1, pct=True)

        raw_factor_df = rank_abs_delta_close_5 * rank_abs_delta_volume_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Absolute_Price_Volume_Change_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ç»å¯¹ä»·é‡å˜åŒ–å› å­ I: rank(abs(delta(close, 10))) * rank(abs(delta(volume, 10)))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        rank_abs_delta_close_10 = close_df.diff(10).abs().rank(axis=1, pct=True)
        rank_abs_delta_volume_10 = volume_df.diff(10).abs().rank(axis=1, pct=True)

        raw_factor_df = rank_abs_delta_close_10 * rank_abs_delta_volume_10
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Volume_Movement_Relationship_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·é‡å˜åŠ¨å…³ç³»å› å­ I: rank(delta(volume, 5)) * rank(delta(close, 5))
        (ä¸ Price-Volume Synchronization Factor I ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        return self.calculate_Price_Volume_Synchronization_Factor_I(period_data)

    def calculate_Short_term_Price_Volume_Interaction_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        çŸ­æœŸä»·é‡äº’åŠ¨å› å­ I: rank(delta(close, 5)) * rank(delta(volume, 5))
        (ä¸ Price-Volume Synchronization Factor I ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        return self.calculate_Price_Volume_Synchronization_Factor_I(period_data)

    # --------------------------------------------------------
    # >>>>>> æ–°å¢å› å­è®¡ç®—æ–¹æ³• (B. ä»·é‡èƒŒç¦»ä¸åè½¬å› å­) <<<<<<
    # --------------------------------------------------------
    def calculate_Price_Volume_Divergence_Factor(self, period_data: Dict) -> pd.DataFrame:
        """
        é‡ä»·èƒŒç¦»å› å­: rank(ä»·æ ¼åŠ¨é‡) - rank(æˆäº¤é‡åŠ¨é‡)
        (å·²åœ¨ calculate_volume_price_divergence ä¸­å®ç°ï¼Œä½†è¿™é‡Œä½¿ç”¨æ–°çš„æ–¹æ³•å)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # ä»·æ ¼åŠ¨é‡ (ä½¿ç”¨ 5æ—¥ pct_change)
        price_momentum = close_df.pct_change(5)
        # æˆäº¤é‡åŠ¨é‡ (ä½¿ç”¨ 5æ—¥ pct_change)
        volume_momentum = volume_df.pct_change(5)

        # é‡ä»·èƒŒç¦»
        divergence = price_momentum.rank(axis=1, pct=True) - volume_momentum.rank(axis=1, pct=True)

        factor_df = divergence.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Negative_Price_Volume_Correlation_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        è´Ÿä»·é‡ç›¸å…³æ€§å› å­ I: -1 * correlation(rank(close), rank(volume), 10)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. æ¯æ—¥æˆªé¢æ’å
        rank_close = close_df.rank(axis=1, pct=True)
        rank_volume = volume_df.rank(axis=1, pct=True)

        # 2. è®¡ç®— 10 æ—¥æ»šåŠ¨ç›¸å…³æ€§ (æ—¶é—´åºåˆ—ç›¸å…³æ€§)
        corr_term_raw = rank_close.rolling(window=10).corr(rank_volume)

        # 3. è®¡ç®—è´Ÿç›¸å…³æ€§
        negative_corr = -1 * corr_term_raw

        factor_df = negative_corr.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # --- åè½¬ä¿¡å·å› å­ ---
    def calculate_Market_Reversal_Capture_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¸‚åœºåè½¬æ•æ‰å› å­ I: rank(delta(volume, 5)) * rank(stddev(close, 5))
        (ä¸ Alpha#3 å…¬å¼ç±»ä¼¼ï¼Œä½†å‘¨æœŸä¸åŒ)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. 5æ—¥æ³¢åŠ¨ç‡: stddev(close, 5)
        volatility_term = close_df.rolling(window=5).std()

        # 2. 5æ—¥æˆäº¤é‡å˜åŒ–: delta(volume, 5)
        delta_volume_term = volume_df.diff(5)

        # 3. æˆªé¢æ’åå¹¶ç›¸ä¹˜
        ranked_volatility = volatility_term.rank(axis=1, pct=True, method='average')
        ranked_delta_volume = delta_volume_term.rank(axis=1, pct=True, method='average')

        raw_factor_df = ranked_volatility * ranked_delta_volume
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Market_Reversal_Timing_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¸‚åœºåè½¬æ—¶æœºå› å­ I: rank(abs(delta(close, 10))) * rank(abs(delta(volume, 10)))
        (ä¸ Absolute_Price_Volume_Change_Factor_I ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        return self.calculate_Absolute_Price_Volume_Change_Factor_I(period_data)

    def calculate_Reversal_Potential_Assessment_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        åè½¬æ½œåŠ›è¯„ä¼°å› å­ I: rank(delta(volume, 5)) * rank(abs(delta(close, 5)))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        rank_abs_delta_close_5 = close_df.diff(5).abs().rank(axis=1, pct=True)
        rank_delta_volume_5 = volume_df.diff(5).rank(axis=1, pct=True)

        raw_factor_df = rank_abs_delta_close_5 * rank_delta_volume_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Pullback_Risk_Identification_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å›è°ƒé£é™©è¯†åˆ«å› å­ I: rank(delta(close, 10)) * rank(delta(volume, 10))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        rank_delta_close_10 = close_df.diff(10).rank(axis=1, pct=True)
        rank_delta_volume_10 = volume_df.diff(10).rank(axis=1, pct=True)

        raw_factor_df = rank_delta_close_10 * rank_delta_volume_10
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Reversal_Signal_Strength_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        åè½¬ä¿¡å·å¼ºåº¦å› å­ I: rank(delta(close, 5)) * rank(abs(delta(volume, 5)))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        rank_delta_close_5 = close_df.diff(5).rank(axis=1, pct=True)
        rank_abs_delta_volume_5 = volume_df.diff(5).abs().rank(axis=1, pct=True)

        raw_factor_df = rank_delta_close_5 * rank_abs_delta_volume_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Trend_Reversal_Warning_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        è¶‹åŠ¿åè½¬é¢„è­¦å› å­ I: rank(correlation(rank(close), rank(volume), 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. æ¯æ—¥æˆªé¢æ’å
        rank_close = close_df.rank(axis=1, pct=True)
        rank_volume = volume_df.rank(axis=1, pct=True)

        # 2. è®¡ç®— 5 æ—¥æ»šåŠ¨ç›¸å…³æ€§
        corr_term_raw = rank_close.rolling(window=5).corr(rank_volume)

        factor_df = corr_term_raw.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # --------------------------------------------------------
    # >>>>>> æ–°å¢å› å­è®¡ç®—æ–¹æ³• (C. æ³¢åŠ¨æ€§ä¸é£é™©å› å­) <<<<<<
    # --------------------------------------------------------
    def calculate_Stock_Volatility_and_Volume_Change_Factor(self, period_data: Dict) -> pd.DataFrame:
        """
        è‚¡ä»·æ³¢åŠ¨æ€§ä¸æˆäº¤é‡å˜åŒ–å› å­: rank(stddev(close, 10)) * rank(delta(volume, 5))
        (ä¸ Alpha#3 å…¬å¼ç›¸åŒï¼Œä½†å‘¨æœŸä¸åŒ)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. 10æ—¥æ³¢åŠ¨ç‡: stddev(close, 10)
        volatility_term = close_df.rolling(window=10).std()

        # 2. 5æ—¥æˆäº¤é‡å˜åŒ–: delta(volume, 5)
        delta_volume_term = volume_df.diff(5)

        # 3. æˆªé¢æ’åå¹¶ç›¸ä¹˜
        ranked_volatility = volatility_term.rank(axis=1, pct=True, method='average')
        ranked_delta_volume = delta_volume_term.rank(axis=1, pct=True, method='average')

        raw_factor_df = ranked_volatility * ranked_delta_volume
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Variance_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼æ–¹å·®å› å­ I: close.rolling(20).var()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        variance_term = close_df.rolling(window=20).var()
        factor_df = variance_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Market_Uncertainty_Measurement_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¸‚åœºä¸ç¡®å®šæ€§åº¦é‡å› å­ I: rank(stddev(close, 10))
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        stddev_term = close_df.rolling(window=10).std()
        factor_df = stddev_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Bollinger_Upper_Band_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¸ƒæ—å¸¦ä¸Šè½¨å› å­ I: close.rolling(20).mean() + 2 * close.rolling(20).std()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ma = close_df.rolling(window=20).mean()
        std = close_df.rolling(window=20).std()
        upper_band = ma + 2 * std
        # å› å­å€¼é€šå¸¸æ˜¯ä»·æ ¼ç›¸å¯¹äºæŒ‡æ ‡çš„ä½ç½®ï¼Œè¿™é‡Œè®¡ç®—ä»·æ ¼ä¸ä¸Šè½¨çš„å·®å€¼å¹¶æ’å
        factor_df = (close_df - upper_band).rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Bollinger_Lower_Band_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¸ƒæ—å¸¦ä¸‹è½¨å› å­ I: close.rolling(20).mean() - 2 * close.rolling(20).std()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ma = close_df.rolling(window=20).mean()
        std = close_df.rolling(window=20).std()
        lower_band = ma - 2 * std
        # å› å­å€¼é€šå¸¸æ˜¯ä»·æ ¼ç›¸å¯¹äºæŒ‡æ ‡çš„ä½ç½®ï¼Œè¿™é‡Œè®¡ç®—ä»·æ ¼ä¸ä¸‹è½¨çš„å·®å€¼å¹¶æ’å
        factor_df = (close_df - lower_band).rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Short_term_Volatility_Volume_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        çŸ­æœŸæ³¢åŠ¨æˆäº¤é‡å› å­ I: rank(stddev(close, 10)) * rank(delta(volume, 5))
        (ä¸ Stock_Volatility_and_Volume_Change_Factor ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        return self.calculate_Stock_Volatility_and_Volume_Change_Factor(period_data)

    def calculate_Long_term_Volatility_Volume_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        é•¿æœŸæ³¢åŠ¨æˆäº¤é‡å› å­ I: rank(stddev(close, 20)) * rank(delta(volume, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        volatility_term = close_df.rolling(window=20).std()  # 20æ—¥æ³¢åŠ¨ç‡
        delta_volume_term = volume_df.diff(5)  # 5æ—¥æˆäº¤é‡å˜åŒ–

        ranked_volatility = volatility_term.rank(axis=1, pct=True)
        ranked_delta_volume = delta_volume_term.rank(axis=1, pct=True)

        raw_factor_df = ranked_volatility * ranked_delta_volume
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Volatility_Volume_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æ³¢åŠ¨æˆäº¤é‡å› å­ I: rank(delta(volume, 10)) * rank(stddev(close, 10))
        (ä¸ Stock_Volatility_and_Volume_Change_Factor ç±»ä¼¼ï¼Œå‘¨æœŸæœ‰å¾®å°å·®å¼‚ï¼Œè¿™é‡Œå®ç°å…¶ç²¾ç¡®å…¬å¼)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        volatility_term = close_df.rolling(window=10).std()  # 10æ—¥æ³¢åŠ¨ç‡
        delta_volume_term = volume_df.diff(10)  # 10æ—¥æˆäº¤é‡å˜åŒ–

        ranked_volatility = volatility_term.rank(axis=1, pct=True)
        ranked_delta_volume = delta_volume_term.rank(axis=1, pct=True)

        raw_factor_df = ranked_delta_volume * ranked_volatility
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Volatility_Volume_Synergy_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æ³¢åŠ¨ç‡æˆäº¤é‡ååŒå› å­ I: rank(stddev(close, 10)) * rank(delta(volume, 10))
        (ä¸ Volatility_Volume_Factor_I ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        return self.calculate_Volatility_Volume_Factor_I(period_data)

    # --- åˆ†å¸ƒå½¢æ€ä¸é£é™©è¯„ä¼°å› å­ (ä½¿ç”¨ pct_change è¿›è¡Œååº¦å’Œå³°åº¦è®¡ç®—) ---
    def calculate_Price_Skewness_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼ååº¦å› å­ I: close.pct_change().rolling(20).skew()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        skewness_term = close_df.pct_change().rolling(window=20).skew()
        factor_df = skewness_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Kurtosis_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼å³°åº¦å› å­ I: close.pct_change().rolling(20).kurtosis()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        kurtosis_term = close_df.pct_change().rolling(window=20).kurtosis()
        factor_df = kurtosis_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Sharpe_Ratio_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¤æ™®æ¯”ç‡å› å­ I: mean(pct_change, 20) / stddev(pct_change, 20)
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        returns_df = close_df.pct_change()

        mean_returns = returns_df.rolling(window=20).mean()
        std_returns = returns_df.rolling(window=20).std()

        # é¿å…é™¤ä»¥é›¶
        sharpe_ratio_term = np.divide(mean_returns, std_returns,
                                      out=np.zeros_like(mean_returns, dtype=float),
                                      where=std_returns != 0)

        factor_df = sharpe_ratio_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Volatility_Risk_Assessment_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æ³¢åŠ¨é£é™©è¯„ä¼°å› å­ I: rank(abs(delta(close, 5))) * rank(stddev(volume, 5))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # rank(abs(delta(close, 5)))
        rank_abs_delta_close_5 = close_df.diff(5).abs().rank(axis=1, pct=True)
        # rank(stddev(volume, 5))
        rank_stddev_volume_5 = volume_df.rolling(window=5).std().rank(axis=1, pct=True)

        raw_factor_df = rank_abs_delta_close_5 * rank_stddev_volume_5
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Risk_Return_Balance_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        é£é™©å›æŠ¥å¹³è¡¡å› å­ I: rank(stddev(close, 5)) * rank(delta(volume, 10))
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        # 1. rank(stddev(close, 5))
        rank_stddev_close_5 = close_df.rolling(window=5).std().rank(axis=1, pct=True)
        # 2. rank(delta(volume, 10))
        rank_delta_volume_10 = volume_df.diff(10).rank(axis=1, pct=True)

        raw_factor_df = rank_stddev_close_5 * rank_delta_volume_10
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Standard_Deviation_Deviation_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æ ‡å‡†å·®åç¦»åº¦å› å­ I: rank((close - mean(close, 30)) / stddev(close, 30))
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']

        ma_30 = close_df.rolling(window=30).mean()
        std_30 = close_df.rolling(window=30).std()

        # é¿å…é™¤ä»¥é›¶
        deviation_term = np.divide(close_df - ma_30, std_30,
                                   out=np.zeros_like(close_df, dtype=float),
                                   where=std_30 != 0)

        factor_df = deviation_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # --------------------------------------------------------
    # >>>>>> æ–°å¢å› å­è®¡ç®—æ–¹æ³• (D. æˆäº¤é‡å½¢æ€å› å­) <<<<<<
    # --------------------------------------------------------
    # Turnover20 å·²æœ‰ calculate_Turnover20_Factor

    def calculate_Volume_Momentum_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æˆäº¤é‡åŠ¨é‡å› å­ I: rank(delta(volume, 10))
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        delta_term = volume_df.diff(10)
        factor_df = delta_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_High_Volume_Screening_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        é«˜æˆäº¤é‡ç­›é€‰å› å­ I: rank(delta(volume, 5))
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        delta_term = volume_df.diff(5)
        factor_df = delta_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Volume_Rate_of_Change_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æˆäº¤é‡å˜åŠ¨é€Ÿç‡å› å­ I: (volume - volume.shift(12)) / volume.shift(12)
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        roc_term = (volume_df - volume_df.shift(12)) / volume_df.shift(12)
        factor_df = roc_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Time_Volume_Moving_Average_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æ—¶é—´æˆäº¤é‡å‡çº¿å› å­ I: volume.rolling(6).mean()
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        ma_term = volume_df.rolling(window=6).mean()
        factor_df = ma_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Time_Volume_Moving_Average_Factor_II(self, period_data: Dict) -> pd.DataFrame:
        """
        æ—¶é—´æˆäº¤é‡å‡çº¿å› å­ II: volume.rolling(20).mean()
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        ma_term = volume_df.rolling(window=20).mean()
        factor_df = ma_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Volume_Exponential_Moving_Average_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æˆäº¤é‡æŒ‡æ•°ç§»åŠ¨å¹³å‡å› å­ I: volume.ewm(span=10).mean()
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        ema_term = volume_df.ewm(span=10).mean()
        factor_df = ema_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Volume_Exponential_Moving_Average_Factor_II(self, period_data: Dict) -> pd.DataFrame:
        """
        æˆäº¤é‡æŒ‡æ•°ç§»åŠ¨å¹³å‡å› å­ II: volume.ewm(span=12).mean()
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        ema_term = volume_df.ewm(span=12).mean()
        factor_df = ema_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Average_Volume_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å¹³å‡æˆäº¤é‡å› å­ I: volume.rolling(5).mean()
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        ma_term = volume_df.rolling(window=5).mean()
        factor_df = ma_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Dynamic_Volume_Ratio_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        åŠ¨æ€æˆäº¤é‡æ¯”ç‡å› å­ I: volume.rolling(5).mean() / volume.rolling(120).mean()
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        ma_5 = volume_df.rolling(window=5).mean()
        ma_120 = volume_df.rolling(window=120).mean()

        # é¿å…é™¤ä»¥é›¶
        ratio_term = np.divide(ma_5, ma_120,
                               out=np.zeros_like(ma_5, dtype=float),
                               where=ma_120 != 0)

        factor_df = ratio_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Volume_Difference_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æˆäº¤é‡å·®å€¼å› å­ I: volume - volume.rolling(10).mean()
        """
        if 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æˆäº¤é‡æ•°æ®")
        volume_df = period_data['æˆäº¤é‡']
        ma_10 = volume_df.rolling(window=10).mean()
        diff_term = volume_df - ma_10
        factor_df = diff_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # --------------------------------------------------------
    # >>>>>> æ–°å¢å› å­è®¡ç®—æ–¹æ³• (E. æŠ€æœ¯æŒ‡æ ‡ä¸å¸‚åœºæƒ…ç»ªå› å­) <<<<<<
    # --------------------------------------------------------
    def calculate_MACD_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        MACD å› å­ I: close.ewm(span=12).mean() - close.ewm(span=26).mean() (å³ MACD ä¸­çš„ DIF çº¿)
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ema_12 = close_df.ewm(span=12, adjust=False).mean()
        ema_26 = close_df.ewm(span=26, adjust=False).mean()
        macd_dif = ema_12 - ema_26
        factor_df = macd_dif.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Commodity_Channel_Index_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å•†å“é€šé“æŒ‡æ•°å› å­ I: 10æ—¥CCIæŒ‡æ ‡ã€‚ (typical_price - typical_price.rolling(10).mean()) / (0.015 * typical_price.rolling(10).std())
        (ä¸ CCI20 ç›¸åŒï¼Œä½†å‘¨æœŸ N=10)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æ—¥æœ€é«˜ä»·' not in period_data or 'æ—¥æœ€ä½ä»·' not in period_data:
            raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·ã€æœ€é«˜ä»·æˆ–æœ€ä½ä»·æ•°æ®")

        close_df = period_data['æ”¶ç›˜ä»·']
        high_df = period_data['æ—¥æœ€é«˜ä»·']
        low_df = period_data['æ—¥æœ€ä½ä»·']
        N = 10

        # 1. è®¡ç®— Typical Price (TP)
        TP_df = (high_df + low_df + close_df) / 3

        # 2. è®¡ç®— TP çš„ N å‘¨æœŸ SMA (SMATP)
        SMATP_df = TP_df.rolling(window=N).mean()

        # 3. è®¡ç®— N å‘¨æœŸå¹³å‡ç»å¯¹åå·® (Mean Deviation)
        # MeanDeviation = SMA(|TP - SMATP|, N)
        MD_df = (TP_df - SMATP_df).abs().rolling(window=N).mean()

        # 4. è®¡ç®— CCI
        MD_df_safe = MD_df.replace(0, np.nan)
        cci_term = (TP_df - SMATP_df) / (0.015 * MD_df_safe)

        factor_df = cci_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # æ³¨ï¼šCR Indicator Factor I å’Œ Money Flow Index Factor I æ¶‰åŠå¤æ‚çš„ä»·æ ¼åˆ†è§£å’Œèµ„é‡‘æµå‘è®¡ç®—ï¼Œæš‚æ—¶è·³è¿‡ï¼Œåªå®ç°ç®€å•æŒ‡æ ‡ã€‚

    def calculate_Overbought_Oversold_Indicator_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        è¶…ä¹°è¶…å–æŒ‡æ ‡å› å­ I: rank((close - delay(close, 1))) / rank(stddev(close, 20))
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']

        # rank((close - delay(close, 1)))
        rank_delta_1 = close_df.diff(1).rank(axis=1, pct=True)
        # rank(stddev(close, 20))
        rank_stddev_20 = close_df.rolling(window=20).std().rank(axis=1, pct=True)

        # é¿å…é™¤ä»¥é›¶
        indicator_term = np.divide(rank_delta_1, rank_stddev_20,
                                   out=np.zeros_like(rank_delta_1, dtype=float),
                                   where=rank_stddev_20 != 0)

        factor_df = indicator_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # æ³¨ï¼šBalance of Power Factor I æ¶‰åŠå¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·å’Œæ”¶ç›˜ä»·çš„å¤æ‚å…³ç³»ï¼Œè‹¥æ•°æ®é¡¹ä¸å…¨æˆ–å…¬å¼å¤æ‚ï¼Œæš‚ä¸å®ç°ã€‚

    def calculate_Price_Bias_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼åç¦»å› å­ I: (close - close.rolling(5).mean()) / close.rolling(5).mean()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ma_5 = close_df.rolling(window=5).mean()
        # é¿å…é™¤ä»¥é›¶
        bias_term = np.divide(close_df - ma_5, ma_5,
                              out=np.zeros_like(close_df, dtype=float),
                              where=ma_5 != 0)

        factor_df = bias_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Bias_Factor_II(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼åç¦»å› å­ II: (close - close.rolling(10).mean()) / close.rolling(10).mean()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ma_10 = close_df.rolling(window=10).mean()
        # é¿å…é™¤ä»¥é›¶
        bias_term = np.divide(close_df - ma_10, ma_10,
                              out=np.zeros_like(close_df, dtype=float),
                              where=ma_10 != 0)

        factor_df = bias_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Bias_Factor_III(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼åç¦»å› å­ III: (close - close.rolling(20).mean()) / close.rolling(20).mean()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ma_20 = close_df.rolling(window=20).mean()
        # é¿å…é™¤ä»¥é›¶
        bias_term = np.divide(close_df - ma_20, ma_20,
                              out=np.zeros_like(close_df, dtype=float),
                              where=ma_20 != 0)

        factor_df = bias_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Bias_Factor_IV(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼åç¦»å› å­ IV: (close - close.rolling(60).mean()) / close.rolling(60).mean()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ma_60 = close_df.rolling(window=60).mean()
        # é¿å…é™¤ä»¥é›¶
        bias_term = np.divide(close_df - ma_60, ma_60,
                              out=np.zeros_like(close_df, dtype=float),
                              where=ma_60 != 0)

        factor_df = bias_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Exponential_Moving_Average_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æŒ‡æ•°ç§»åŠ¨å¹³å‡å› å­ I: close.ewm(span=5).mean()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        ema_term = close_df.ewm(span=5, adjust=False).mean()
        factor_df = ema_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Weekly_Close_Rank_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        å‘¨æ”¶ç›˜æ’åå› å­ I: close / close.rolling(250).max()
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        max_250 = close_df.rolling(window=250).max()
        # é¿å…é™¤ä»¥é›¶
        rank_term = np.divide(close_df, max_250,
                              out=np.zeros_like(close_df, dtype=float),
                              where=max_250 != 0)

        factor_df = rank_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Price_Range_Analysis_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ä»·æ ¼åŒºé—´åˆ†æå› å­ I: rank(open - close) * rank(high - low)
        """
        if 'å¼€ç›˜ä»·' not in period_data or 'æ”¶ç›˜ä»·' not in period_data or \
                'æ—¥æœ€é«˜ä»·' not in period_data or 'æ—¥æœ€ä½ä»·' not in period_data:
            raise ValueError("ç¼ºå°‘å¼€ç›˜ä»·ã€æ”¶ç›˜ä»·ã€æœ€é«˜ä»·æˆ–æœ€ä½ä»·æ•°æ®")

        open_df = period_data['å¼€ç›˜ä»·']
        close_df = period_data['æ”¶ç›˜ä»·']
        high_df = period_data['æ—¥æœ€é«˜ä»·']
        low_df = period_data['æ—¥æœ€ä½ä»·']

        # rank(open - close)
        rank_open_close = (open_df - close_df).rank(axis=1, pct=True)
        # rank(high - low)
        rank_high_low = (high_df - low_df).rank(axis=1, pct=True)

        raw_factor_df = rank_open_close * rank_high_low
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    # --------------------------------------------------------
    # >>>>>> æ–°å¢å› å­è®¡ç®—æ–¹æ³• (F. å¸‚åœºè”åŠ¨ä¸ç›¸å¯¹å¼ºå¼±å› å­) <<<<<<
    # --------------------------------------------------------
    # æ³¨ï¼š Market Relative Strength Factor I, Market Trend Correlation Factor I, Short-term Market Correlation Factor I æ¶‰åŠå¸‚åœºæŒ‡æ•°ï¼Œæš‚ä¸å®ç°ã€‚

    def calculate_Time_Series_Ranking_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        æ—¶é—´åºåˆ—æ’åå› å­ I: rank(Ts_Rank(close, 20))
        """
        if 'æ”¶ç›˜ä»·' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']

        # Ts_Rank(close, 20) æ˜¯æŒ‡å¯¹æ¯åªè‚¡ç¥¨ï¼Œè®¡ç®—å…¶å½“å‰æ”¶ç›˜ä»·åœ¨è¿‡å»20ä¸ªäº¤æ˜“æ—¥ä¸­çš„æ—¶é—´åºåˆ—æ’å (0-19)
        def ts_rank(series, window):
            return series.rolling(window).apply(
                lambda x: x.iloc[-1] in np.sort(x) and np.where(np.sort(x) == x.iloc[-1])[0][0] if len(
                    x) == window else np.nan, raw=False)

        ts_rank_term = close_df.apply(lambda x: x.rolling(window=20).apply(
            lambda y: pd.Series(y.rank(pct=True).iloc[-1]), raw=False
        ), axis=0)

        # å¯¹æ—¶é—´åºåˆ—æ’åç»“æœå†è¿›è¡Œæˆªé¢æ’å
        factor_df = ts_rank_term.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')

    def calculate_Relative_Volatility_Factor_I(self, period_data: Dict) -> pd.DataFrame:
        """
        ç›¸å¯¹æ³¢åŠ¨æ€§å› å­ I: rank(delta(close, 10)) * rank(delta(volume, 10))
        (ä¸ Pullback_Risk_Identification_Factor_I ç›¸åŒï¼Œä¿ç•™ä»¥ç¬¦åˆå‘½åè¦æ±‚)
        """
        if 'æ”¶ç›˜ä»·' not in period_data or 'æˆäº¤é‡' not in period_data: raise ValueError("ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æˆäº¤é‡æ•°æ®")
        close_df = period_data['æ”¶ç›˜ä»·']
        volume_df = period_data['æˆäº¤é‡']

        rank_delta_close_10 = close_df.diff(10).rank(axis=1, pct=True)
        rank_delta_volume_10 = volume_df.diff(10).rank(axis=1, pct=True)

        raw_factor_df = rank_delta_close_10 * rank_delta_volume_10
        factor_df = raw_factor_df.rank(axis=1, pct=True)
        factor_df.columns.name = 'code'
        factor_df.index.name = 'date'
        return factor_df.dropna(how='all')


    def prepare_panel_data(self, factor_name: str) -> pd.DataFrame:
        """
        å‡†å¤‡é¢æ¿æ•°æ® (ç»Ÿä¸€å¤„ç†åŸºç¡€å› å­å’Œæ¯æ—¥æ»šåŠ¨åˆæˆå› å­)
        - å°†æ‰€æœ‰æ—¶é—´åºåˆ—å®½è¡¨è½¬ä¸ºé•¿è¡¨å¹¶åˆå¹¶
        """
        panel_data = []

        for period_name, period_data in self.all_data.items():
            factor_df = None

            # ä¼˜å…ˆæ£€æŸ¥åˆæˆå› å­ (ç°å·²æ”¹ä¸ºæ¯æ—¥æ»šåŠ¨è®¡ç®—ï¼Œè¿”å›æ—¶é—´åºåˆ—å®½è¡¨)
            if factor_name in self.synthetic_factors and period_name in self.synthetic_factors[factor_name]:
                factor_df = self.synthetic_factors[factor_name][period_name]
            # å…¶æ¬¡æ£€æŸ¥åŸºç¡€å› å­ (æœ¬èº«å°±æ˜¯æ—¶é—´åºåˆ—å®½è¡¨)
            elif factor_name in period_data:
                factor_df = period_data[factor_name]

            if factor_df is not None and not factor_df.empty:
                # ä½¿ç”¨ stack å°†å®½è¡¨ (Index=date, Columns=code) è½¬ä¸ºé•¿è¡¨
                try:
                    long_factor_df = factor_df.stack().reset_index()
                    long_factor_df.columns = ['date', 'code', factor_name]
                    long_factor_df['period'] = period_name
                    panel_data.append(long_factor_df)
                except Exception as e:
                    print(f"âš ï¸  {period_name} - {factor_name} æ•°æ®è½¬æ¢å¤±è´¥: {e}")
                    continue

        result_df = pd.concat(panel_data, ignore_index=True) if panel_data else pd.DataFrame()

        if not result_df.empty:
            # ç¡®ä¿æ—¥æœŸæ˜¯ datetime ç±»å‹
            result_df['date'] = pd.to_datetime(result_df['date'])
            print(f"\nâœ… å› å­ '{factor_name}' é¢æ¿æ•°æ®:")
            print(f"   æ—¶é—´ç‚¹: {result_df['date'].nunique()}")
            print(f"   è‚¡ç¥¨æ•°: {result_df['code'].nunique()}")
            print(f"   æ€»è®°å½•: {len(result_df)}")
        else:
            print(f"\nâš ï¸  å› å­ '{factor_name}' æ— æ•°æ®")

        return result_df

    def calculate_returns(self) -> pd.DataFrame:
        """è®¡ç®—æ”¶ç›Šç‡"""
        returns_data = []

        for period_name, period_data in self.all_data.items():
            if 'æ”¶ç›˜ä»·' in period_data:
                close_df = period_data['æ”¶ç›˜ä»·']
                # è®¡ç®—æ—¥æ”¶ç›Šç‡
                returns_df = close_df.pct_change()

                # å°†æ”¶ç›Šç‡å®½è¡¨è½¬ä¸ºé•¿è¡¨
                long_returns_df = returns_df.stack().reset_index()
                long_returns_df.columns = ['date', 'code', 'return']
                returns_data.append(long_returns_df)

        result_df = pd.concat(returns_data, ignore_index=True) if returns_data else pd.DataFrame()

        if not result_df.empty:
            # ç¡®ä¿æ—¥æœŸæ˜¯ datetime ç±»å‹
            result_df['date'] = pd.to_datetime(result_df['date'])
            # æ¸…ç† Inf/-Inf (é™¤ä»¥0å¯èƒ½äº§ç”Ÿ)
            result_df = result_df.replace([np.inf, -np.inf], np.nan).dropna(subset=['return'])
            print(f"\nğŸ“ˆ æ”¶ç›Šç‡æ•°æ®: {len(result_df)} æ¡è®°å½•")
        return result_df

    def analyze_factor(self, factor_name: str, plot: bool = False):
        """åˆ†æå•ä¸ªå› å­"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ” åˆ†æå› å­: {factor_name}")
        print(f"{'=' * 60}")

        # å‡†å¤‡å› å­æ•°æ® (å·²æ˜¯æ¯æ—¥æ—¶é—´åºåˆ—)
        factor_df = self.prepare_panel_data(factor_name)
        if factor_df.empty:
            print(f"âŒ å› å­ {factor_name} æ— æ•°æ®")
            return

        BASE_OUTPUT_DIR = Path("C:/Users/cufet/Desktop/Factor_Analysis_Output")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        BASE_OUTPUT_DIR.mkdir(exist_ok=True)

        # å®Œæ•´çš„ç»å¯¹æ–‡ä»¶è·¯å¾„
        excel_path = BASE_OUTPUT_DIR / f"{factor_name}_panel_data.xlsx"

        try:
            factor_df.to_excel(excel_path, index=False)
            print(f"ğŸ’¾ å› å­é¢æ¿æ•°æ®å·²ä¿å­˜åˆ°ç»å¯¹è·¯å¾„: {excel_path.resolve()}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å› å­é¢æ¿æ•°æ®å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„æƒé™: {e}")

        # å‡†å¤‡æ”¶ç›Šæ•°æ®
        returns_df = self.calculate_returns()

        # åˆå¹¶æ•°æ®
        # ç»Ÿä¸€åˆ—åä»¥ä¾›ä¸‹ä¸€æ­¥åˆ†æ
        merged_data = factor_df.merge(returns_df, on=['date', 'code'], how='inner')

        if merged_data.empty:
            print("âŒ æ— æœ‰æ•ˆæ•°æ®ç”¨äºåˆ†æ")
            dates = factor_df['date'].unique()
            if len(dates) <= 1:
                print("æç¤ºï¼šå½“å‰æ•°æ®é›†ä¸­äº¤æ˜“æ—¥è¿‡å°‘ï¼Œæ— æ³•è¿›è¡Œ T->T+1 çš„æ—¶é—´åºåˆ—åˆ†æã€‚")
            return

        print(f"âœ… åˆå¹¶æ•°æ®: {len(merged_data)} æ¡è®°å½•")
        print(f"   æ—¶é—´èŒƒå›´: {merged_data['date'].min()} åˆ° {merged_data['date'].max()}")
        print(f"   è‚¡ç¥¨æ•°é‡: {merged_data['code'].nunique()}")

        # æ‰§è¡Œåˆ†æ
        results, daily_returns = self._perform_analysis(merged_data, factor_name)

        # å¯è§†åŒ–
        if plot:
            self._create_plots(results, factor_name, merged_data)
            if 'long_short_returns' in daily_returns and not daily_returns['long_short_returns'].empty:
                self._plot_cumulative_return(daily_returns['long_short_returns'], factor_name)

        self.factor_results[factor_name] = results
        return results

    def _perform_analysis(self, data: pd.DataFrame, factor_name: str) -> tuple[Dict, Dict]:
        """æ‰§è¡Œå› å­åˆ†æ (å·²ä¿®å¤ T->T+1 åŒ¹é…é€»è¾‘, å¢åŠ ICè‡ªç›¸å…³æ€§å’Œå¤šç©ºç»„åˆæ”¶ç›Šåºåˆ—)"""
        results = {}
        daily_returns = {}  # ç”¨äºå­˜å‚¨å¤šç©ºç»„åˆæ¯æ—¥æ”¶ç›Šåºåˆ—

        # ICåˆ†æ
        ic_series = []
        Rankic_series = []
        # è·å–æ‰€æœ‰å”¯ä¸€çš„ã€æŒ‰å‡åºæ’åˆ—çš„æ—¥æœŸ
        dates = sorted(data['date'].unique())

        # ç”¨äºåˆ†æ¡£åˆ†æ (æ¯æ—¥å¤šç©ºæ”¶ç›Š)
        long_short_daily_returns = []

        # æ³¨æ„ï¼šè¿™é‡Œ date[i] æ˜¯å› å­æ—¥æœŸ Tï¼Œdate[i+1] æ˜¯æ”¶ç›Šç‡æ—¥æœŸ T+1
        for i in range(len(dates) - 1):
            current_date = dates[i]
            next_date = dates[i + 1]

            # T æ—¥çš„å› å­å€¼
            current_factors = data[data['date'] == current_date][['code', factor_name]].copy()
            # T+1 æ—¥çš„æ”¶ç›Šç‡
            next_returns = data[data['date'] == next_date][['code', 'return']].copy()

            # åˆå¹¶ T æ—¥å› å­å’Œ T+1 æ—¥æ”¶ç›Š
            merged = current_factors.merge(next_returns, on='code', how='inner')

            if len(merged) > 20:  # æœ€å°è‚¡ç¥¨æ•°é‡è¦æ±‚ (ä¸ºåˆ†æ¡£å¤šç©ºç•™å‡ºä½™é‡)
                # --- RankIC è®¡ç®— ---
                ic = merged[factor_name].corr(merged['return'], method='pearson')
                Rankic = merged[factor_name].corr(merged['return'], method='spearman')
                if not np.isnan(ic):
                    ic_series.append(ic)
                if not np.isnan(Rankic):
                    Rankic_series.append(Rankic)

                # --- åˆ†æ¡£å¤šç©ºæ”¶ç›Šè®¡ç®— ---
                try:
                    # Tæ—¥åˆ†æ¡£
                    merged['decile'] = pd.qcut(
                        merged[factor_name], 5, labels=False, duplicates='drop'
                    )

                    # ç¡®ä¿åˆ†æ¡£åœ¨ 0-9 ä¹‹é—´
                    if merged['decile'].min() == 0 and merged['decile'].max() == 4:
                        # æœ€é«˜æ¡£ (9) å¹³å‡æ”¶ç›Š - æœ€ä½æ¡£ (0) å¹³å‡æ”¶ç›Š
                        return_4 = merged[merged['decile'] == 4]['return'].mean()
                        return_0 = merged[merged['decile'] == 0]['return'].mean()
                        long_short_return = return_4 - return_0
                        long_short_daily_returns.append(pd.Series(long_short_return, index=[next_date]))
                except Exception:
                    # å¯èƒ½æ•°æ®ä¸è¶³å¯¼è‡´åˆ†æ¡£å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸€å¤©
                    pass

        if ic_series:
            # ICåºåˆ—çš„ç´¢å¼•åº”è¯¥å¯¹åº”æ”¶ç›Šç‡æ—¥æœŸ (T+1 æ—¥)
            ic_series = pd.Series(ic_series, index=dates[1:len(ic_series) + 1])
            ic_series = ic_series[(ic_series != 0) & (ic_series.notna()) & (ic_series != '')]
            monthly_ic_mean = ic_series.resample('M').mean()
            annual_ic_mean = ic_series.resample('Y').mean()
            Rankic_series = pd.Series(Rankic_series, index=dates[1:len(Rankic_series) + 1])
            Rankic_series = Rankic_series[(Rankic_series != 0) & (ic_series.notna()) & (Rankic_series != '')]
            results['ic_series'] = ic_series
            results['annual_ic_mean'] = annual_ic_mean.mean()
            results['monthly_ic_mean'] = monthly_ic_mean.mean()
            results['Rankic_series'] = Rankic_series
            results['ic_mean'] = ic_series.mean()
            results['Rankic_mean'] = Rankic_series.mean()
            results['ic_std'] = ic_series.std()
            results['ir'] = results['ic_mean'] / results['ic_std'] if results['ic_std'] != 0 else 0
            results['win_rate'] = (ic_series > 0).mean() if results['ic_mean'] >= 0 else (ic_series < 0).mean()
            results['factor_direction'] = 'æ­£å› å­' if results['ic_mean'] > 0 else 'è´Ÿå› å­'

            # è¡¥å……ï¼šIC è‡ªç›¸å…³æ€§
            autocorr_1 = self._calculate_ic_autocorrelation(ic_series, lag=1)
            results['ic_autocorr_1'] = autocorr_1

            print(f"ğŸ“Š ICåˆ†æç»“æœ:")
            print(f"   ICå‡å€¼: {results['ic_mean']:.4f}")
            print(f"   æœˆåº¦ICå‡å€¼: {results['monthly_ic_mean']:.4f}")
            print(f"   å¹´åº¦ICå‡å€¼: {results['annual_ic_mean']:.4f}")
            print(f"   RankICå‡å€¼: {results['Rankic_mean']:.4f}")
            # print(f"   ICæ ‡å‡†å·®: {results['ic_std']:.4f}")
            print(f"   IR: {results['ir']:.3f}")
            print(f"   èƒœç‡: {results['win_rate']:.2%}")
            print(f"   ICè‡ªç›¸å…³æ€§ (Lag 1): {autocorr_1:.4f}")
            print(f"   å› å­æ–¹å‘: {results['factor_direction']}")

        # æ¯æ—¥å¤šç©ºç»„åˆæ”¶ç›Šåºåˆ—
        if long_short_daily_returns:
            daily_returns['long_short_returns'] = pd.concat(long_short_daily_returns)

        # åˆ†æ¡£åˆ†æ (ä¸ IC åˆ†æä½¿ç”¨ç›¸åŒçš„ T->T+1 é”™ä½é€»è¾‘)
        decile_returns_mean = self._decile_analysis_mean(data, factor_name)
        if decile_returns_mean is not None:
            results['decile_returns_mean'] = decile_returns_mean
            results['monotonicity'] = self._calculate_monotonicity(decile_returns_mean)
            print(f"   å•è°ƒæ€§: {results['monotonicity']:.3f}")

        return results, daily_returns

    def _calculate_ic_autocorrelation(self, ic_series: pd.Series, lag: int = 1) -> float:
        """
        è®¡ç®— IC åºåˆ—çš„è‡ªç›¸å…³æ€§
        """
        if len(ic_series) <= lag:
            return 0.0
        # å°†åºåˆ—é”™ä½ lag æœŸ
        lagged_ic = ic_series.shift(lag)
        # è®¡ç®— Pearson ç›¸å…³ç³»æ•° (IC å€¼æœ¬èº«å°±æ˜¯æ•°å€¼ï¼Œç”¨ Pearson å³å¯)
        # æ’é™¤ NaN å€¼
        valid_data = pd.DataFrame({'ic': ic_series, 'lagged_ic': lagged_ic}).dropna()

        if len(valid_data) < 2:
            return 0.0

        corr, _ = pearsonr(valid_data['ic'], valid_data['lagged_ic'])
        return corr

    def _decile_analysis_mean(self, data: pd.DataFrame, factor_name: str) -> Optional[pd.Series]:
        """åˆ†æ¡£ç»„åˆåˆ†æ (è¿”å›æ‰€æœ‰æœŸå¹³å‡æ”¶ç›Š)"""
        try:
            all_decile_returns = []
            dates = sorted(data['date'].unique())

            for i in range(len(dates) - 1):
                # T æ—¥çš„å› å­æ•°æ®
                current_data = data[data['date'] == dates[i]].copy()
                # T+1 æ—¥çš„æ”¶ç›Šæ•°æ®
                next_data = data[data['date'] == dates[i + 1]]

                if len(current_data) < 20:  # æœ€å°‘20åªè‚¡ç¥¨
                    continue

                # å½“å‰æœŸåˆ†æ¡£ (Tæ—¥)
                # ä½¿ç”¨ labels=False è¿”å›åˆ†æ¡£æ•°å­— 0-9
                current_data['decile'] = pd.qcut(
                    current_data[factor_name], 5, labels=False, duplicates='drop'
                )

                # åˆå¹¶ä¸‹ä¸€æœŸæ”¶ç›Š (T+1æ—¥)
                merged = current_data.merge(
                    next_data[['code', 'return']], on='code', suffixes=('', '_next'), how='inner'
                )

                if not merged.empty:
                    # è®¡ç®—æ¯ä¸ªåˆ†æ¡£åœ¨ T+1 æ—¥çš„å¹³å‡æ”¶ç›Š
                    decile_return = merged.groupby('decile')['return_next'].mean()
                    all_decile_returns.append(decile_return)

            if all_decile_returns:
                # å¯¹æ‰€æœ‰æ—¶é—´æ®µçš„å¹³å‡æ”¶ç›Šå–å¹³å‡
                # é‡æ–°è®¾ç½®ç´¢å¼•å
                mean_returns = pd.DataFrame(all_decile_returns).mean()
                mean_returns.index = [f'Decile {i + 1}' for i in mean_returns.index]
                return mean_returns

        except Exception as e:
            print(f"åˆ†æ¡£åˆ†æé”™è¯¯: {e}")

        return None

    def _calculate_monotonicity(self, decile_returns: pd.Series) -> float:
        """è®¡ç®—å•è°ƒæ€§"""
        if len(decile_returns) < 2:
            return 0
        # å¯¹åˆ†æ¡£æ•°å­— (0, 1, ..., 9) å’Œå¹³å‡æ”¶ç›Šè¿›è¡Œç›¸å…³æ€§åˆ†æ
        ranks = np.arange(len(decile_returns))
        correlation = np.corrcoef(ranks, decile_returns.values)[0, 1]
        return correlation if not np.isnan(correlation) else 0

    def _create_plots(self, results: Dict, factor_name: str, data: pd.DataFrame):
        # ç®€æ´ä¸‰è‰²é…è‰²
        colors = ['#1f77b4', '#d62728', '#7f7f7f']  # è“è‰²ã€çº¢è‰²ã€ç°è‰²
        # å›¾ï¼šåˆ†æ¡£ç»„åˆæ”¶ç›ŠæŸ±çŠ¶å›¾
        if 'decile_returns_mean' in results and len(results['decile_returns_mean']) > 0:
            plt.figure(figsize=(10, 7))  # å¢åŠ å›¾è¡¨å°ºå¯¸ï¼Œä¸ºæ ‡ç­¾ç•™å‡ºæ›´å¤šç©ºé—´
            decile_returns = results['decile_returns_mean']
            x_labels = [i for i in range(1, len(decile_returns) + 1)]
            # å¹³å‡æ—¥æ”¶ç›Šè½¬å¹´åŒ–æ”¶ç›Š
            annualized_returns = (1 + decile_returns.values) ** 252 - 1
            y_data_percent = annualized_returns * 100  # å¹´åŒ–ç™¾åˆ†æ¯”æ”¶ç›Š

            bar_width = 1.0
            bars = plt.bar(x_labels, y_data_percent,
                           width=bar_width,
                           color=colors[0], alpha=1, edgecolor='white', linewidth=0.5)

            # è´Ÿæ”¶ç›ŠæŸ±å­ç”¨çº¢è‰²
            for i, bar in enumerate(bars):
                height = bar.get_height()
                if height < 0:
                    bar.set_color(colors[1])

            # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ ‡ç­¾ä½ç½®ä¼˜åŒ– (é˜²æ­¢é‡å ) ---
            # ç¡®å®šå›¾è¡¨çš„Yè½´å®é™…æ•°æ®æ˜¾ç¤ºèŒƒå›´ï¼Œä¸ºæ ‡ç­¾åç§»é‡æä¾›å‚è€ƒ
            y_min_data, y_max_data = np.min(y_data_percent), np.max(y_data_percent)
            y_data_span = y_max_data - y_min_data

            # è®¾ç½®ä¸€ä¸ªåŸºäºæ•°æ®èŒƒå›´çš„åŠ¨æ€æœ€å°åç§»é‡
            # ç¡®ä¿å³ä½¿æ•°æ®é‡å¾ˆå°ï¼Œæ ‡ç­¾ä¹Ÿèƒ½æœ‰æ¸…æ™°çš„é—´è·
            min_label_offset = max(y_data_span * 0.03, 0.005)  # æœ€å°åç§»é‡ä¸ºæ•°æ®èŒƒå›´çš„3%æˆ–0.005%

            for i, bar in enumerate(bars):
                height = bar.get_height()

                # æ ‡ç­¾æ–‡æœ¬
                label_text = f'{height:.2f}%'

                # æ ¹æ®æŸ±å­é«˜åº¦æ­£è´Ÿï¼Œå†³å®šæ ‡ç­¾çš„å‚ç›´å¯¹é½å’Œåˆå§‹åç§»æ–¹å‘
                if height >= 0:
                    va = 'bottom'
                    # æ ‡ç­¾æ”¾åœ¨æŸ±å­ä¸Šæ–¹çš„å›ºå®šåç§»é‡
                    offset = min_label_offset
                else:
                    va = 'top'
                    # æ ‡ç­¾æ”¾åœ¨æŸ±å­ä¸‹æ–¹çš„å›ºå®šåç§»é‡
                    offset = -min_label_offset

                # å¦‚æœæŸ±å­é«˜åº¦ä¸º0ï¼Œç‰¹æ®Šå¤„ç†æ ‡ç­¾ä½ç½®ï¼Œç›´æ¥åœ¨0çº¿ç¨ä¸Šæ–¹æ˜¾ç¤º
                if np.isclose(height, 0, atol=0.001):  # ä½¿ç”¨ np.isclose å¤„ç†æµ®ç‚¹æ•°æ¥è¿‘0çš„æƒ…å†µ
                    label_text = '0.00%'
                    va = 'bottom'
                    offset = min_label_offset  # ç¡®ä¿åœ¨0çº¿ä¹‹ä¸Š

                # ç»˜åˆ¶æ ‡ç­¾
                plt.text(bar.get_x() + bar.get_width() / 2, height + offset,
                         label_text, ha='center', va=va,
                         fontsize=10,
                         color='black'  # ç»Ÿä¸€æ ‡ç­¾é¢œè‰²
                         )

            plt.xlim(0.5, len(decile_returns) + 0.5)

            # --- å…³é”®ä¿®æ”¹ 2: ä¼˜åŒ–Yè½´èŒƒå›´å’Œåˆ»åº¦ ---
            # ç¡®ä¿Yè½´åŒ…å«æ‰€æœ‰æ•°æ®ç‚¹å’Œå…¶æ ‡ç­¾
            # è·å–æ‰€æœ‰æ ‡ç­¾çš„yä½ç½®ï¼Œä»¥ä¾¿ç¡®å®šä¸€ä¸ªåˆé€‚çš„Yè½´ä¸Šé™
            all_y_labels_pos = []
            for i, bar in enumerate(bars):
                height = bar.get_height()
                if height >= 0:
                    all_y_labels_pos.append(height + min_label_offset)
                else:
                    all_y_labels_pos.append(height - min_label_offset)

            # ç»“åˆæ•°æ®æœ¬èº«çš„èŒƒå›´å’Œæ ‡ç­¾çš„æœ€é«˜/æœ€ä½ä½ç½®æ¥è®¾ç½®Yè½´
            current_y_min = y_min_data
            current_y_max = y_max_data

            # å¦‚æœæœ‰æ ‡ç­¾ï¼Œç¡®ä¿Yè½´èƒ½è¦†ç›–æ‰€æœ‰æ ‡ç­¾
            if all_y_labels_pos:
                current_y_max = max(current_y_max, np.max(all_y_labels_pos))
                current_y_min = min(current_y_min, np.min(all_y_labels_pos))

            # å¢åŠ é¢å¤–çš„ä¸Šä¸‹è¾¹è·ï¼Œä½¿å›¾è¡¨ä¸æ‹¥æŒ¤
            # æ ¹æ®å®é™…æ•°æ®èŒƒå›´åŠ¨æ€è°ƒæ•´ Y è½´çš„ä¸Šä¸‹è¾¹ç•Œ
            # é¿å…å½“æ‰€æœ‰æ”¶ç›Šéƒ½é›†ä¸­åœ¨ç‹­çª„åŒºé—´æ—¶ï¼Œå›¾è¡¨ä»ç„¶æ˜¾å¾—å¤ªç©º
            y_range_padding = (current_y_max - current_y_min) * 0.15  # å¢åŠ 15%çš„ä¸Šä¸‹è¾¹è·

            # ç¡®ä¿ Y è½´ä¸‹é™ä¸ä¼šè¿‡é«˜ï¼Œå¦‚æœæ‰€æœ‰å€¼éƒ½æ˜¯æ­£æ•°ï¼Œç¡®ä¿èƒ½çœ‹åˆ°0çº¿
            y_lower_bound = min(current_y_min - y_range_padding,
                                0 if y_min_data > 0 else current_y_min - y_range_padding)
            y_upper_bound = current_y_max + y_range_padding

            if y_lower_bound == y_upper_bound:  # é¿å…é™¤é›¶é”™è¯¯æˆ–èŒƒå›´ä¸º0
                y_lower_bound -= 0.1
                y_upper_bound += 0.1

            plt.ylim(y_lower_bound, y_upper_bound)

            # ç§»é™¤Yè½´åˆ»åº¦æ ‡ç­¾ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æœ‰æŸ±é¡¶æ ‡ç­¾
            plt.yticks([])

            plt.title(f'åˆ†æ¡£ç»„åˆå¹³å‡æ”¶ç›Š - {factor_name}', fontsize=16, fontweight='bold', pad=20)  # å¢åŠ æ ‡é¢˜ä¸å›¾è¡¨çš„é—´è·
            plt.xlabel('åˆ†æ¡£ (1:æœ€ä½, 5:æœ€é«˜)', fontsize=12)
            plt.ylabel('å¹´åŒ–å¹³å‡æ”¶ç›Š (%)', fontsize=12)
            plt.xticks(x_labels, fontsize=5)  # ç¡®ä¿Xè½´åˆ»åº¦æ˜¯ 1 åˆ° 10
            plt.axhline(y=0, color='black', linewidth=1)  # 0çº¿
            plt.grid(False)  # ç§»é™¤èƒŒæ™¯ç½‘æ ¼

            # è°ƒæ•´å¸ƒå±€ï¼Œé˜²æ­¢å…ƒç´ é‡å 
            plt.tight_layout()

            # ä¿å­˜åˆ°æ¡Œé¢
            save_path = f'C:/Users/cufet/Desktop/{factor_name}_åˆ†æ¡£æ”¶ç›Š.png'
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()

            print(f"âœ… å›¾è¡¨å·²ä¿å­˜åˆ°æ¡Œé¢: {save_path}")
    #
    def _plot_cumulative_return(self, daily_long_short_returns: pd.Series, factor_name: str):
        """
        ç»˜åˆ¶å¤šç©ºç»„åˆçš„ç´¯è®¡èµ°åŠ¿å›¾ (å‡€å€¼æ›²çº¿)
        """
        # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡ (å‡€å€¼æ›²çº¿ï¼š(1 + R1) * (1 + R2) * ... - 1)
        # R = daily_returns
        # å‡€å€¼ = (1 + R).cumprod()
        cumulative_returns = (1 + daily_long_short_returns).cumprod()

        plt.figure(figsize=(10, 6))

        # ç»˜åˆ¶å‡€å€¼æ›²çº¿
        plt.plot(cumulative_returns.index, cumulative_returns.values,
                 color='#d62728', linewidth=2, label='å¤šç©ºç»„åˆå‡€å€¼')

        plt.title(f'å¤šç©ºç»„åˆç´¯è®¡å‡€å€¼èµ°åŠ¿ - {factor_name}', fontsize=14, fontweight='bold')
        plt.xlabel('æ—¥æœŸ')
        plt.ylabel('ç´¯è®¡å‡€å€¼')
        plt.grid(False, alpha=0)
        plt.legend()

        # æ ¼å¼åŒ–xè½´æ—¥æœŸ
        plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))
        plt.gcf().autofmt_xdate()  # è‡ªåŠ¨æ—‹è½¬æ—¥æœŸæ ‡ç­¾

        # ä¿å­˜åˆ°æ¡Œé¢
        plt.savefig(f'C:/Users/cufet/Desktop/{factor_name}_ç´¯è®¡èµ°åŠ¿å›¾.png', dpi=300, bbox_inches='tight')
        plt.close()

        print(f"âœ… å›¾è¡¨å·²ä¿å­˜åˆ°æ¡Œé¢: {factor_name}_ç´¯è®¡èµ°åŠ¿å›¾.png")


def main():
    analyzer = CS500FactorAnalyzer(data_folder="C:/Users/cufet/Desktop/è®­ç»ƒé›†")
    analyzer.load_all_periods()
    # å¯é€‰ï¼šæ£€æŸ¥åŠ è½½çš„æ•°æ®
    print(analyzer.all_data.keys())
    print("\nğŸ”§ å¼€å§‹è®¡ç®—åˆæˆå› å­...")
    # Alphaå› å­çš„è®¡ç®—é€»è¾‘å·²ä¿®æ”¹ä¸ºæ¯æ—¥æ»šåŠ¨
    analyzer.calculate_synthetic_factor("Alpha#1", analyzer.calculate_alpha1)
    analyzer.calculate_synthetic_factor("Alpha#2", analyzer.calculate_alpha2)
    analyzer.calculate_synthetic_factor("Alpha#3", analyzer.calculate_alpha3)
    analyzer.calculate_synthetic_factor("ROC6", analyzer.calculate_ROC6)
    analyzer.calculate_synthetic_factor("BIAS60", analyzer.calculate_BIAS60)
    analyzer.calculate_synthetic_factor("CCI20", analyzer.calculate_CCI20)
    analyzer.calculate_synthetic_factor("WVAD6", analyzer.calculate_WVAD6)
    analyzer.calculate_synthetic_factor("EP", analyzer.calculate_EP_Factor)
    analyzer.calculate_synthetic_factor("ROE", analyzer.calculate_ROE_Factor)
    analyzer.calculate_synthetic_factor("EPSå¢é•¿", analyzer.calculate_EPS_Growth_Factor)
    analyzer.calculate_synthetic_factor("Turnover20", analyzer.calculate_Turnover20_Factor)
    analyzer.calculate_synthetic_factor("åŠ¨é‡ä»·å€¼å¤åˆ", analyzer.calculate_momentum_value_composite)
    analyzer.calculate_synthetic_factor("æ³¢åŠ¨è°ƒæ•´ä»·å€¼", analyzer.calculate_vol_adjusted_value)
    analyzer.calculate_synthetic_factor("é‡ä»·èƒŒç¦»", analyzer.calculate_volume_price_divergence)
    analyzer.calculate_synthetic_factor("ç›ˆåˆ©å¢é•¿", analyzer.calculate_profitability_growth)
    analyzer.calculate_synthetic_factor("Alpha#1", analyzer.calculate_alpha1)
    analyzer.calculate_synthetic_factor("Alpha#2", analyzer.calculate_alpha2)
    analyzer.calculate_synthetic_factor("Alpha#3", analyzer.calculate_alpha3)
    analyzer.calculate_synthetic_factor("ROC6", analyzer.calculate_ROC6)
    analyzer.calculate_synthetic_factor("BIAS60", analyzer.calculate_BIAS60)
    analyzer.calculate_synthetic_factor("CCI20", analyzer.calculate_CCI20)
    analyzer.calculate_synthetic_factor("WVAD6", analyzer.calculate_WVAD6)
    analyzer.calculate_synthetic_factor("EP", analyzer.calculate_EP_Factor)
    analyzer.calculate_synthetic_factor("ROE", analyzer.calculate_ROE_Factor)
    analyzer.calculate_synthetic_factor("EPSå¢é•¿", analyzer.calculate_EPS_Growth_Factor)
    analyzer.calculate_synthetic_factor("Turnover20", analyzer.calculate_Turnover20_Factor)
    analyzer.calculate_synthetic_factor("åŠ¨é‡ä»·å€¼å¤åˆ", analyzer.calculate_momentum_value_composite)
    analyzer.calculate_synthetic_factor("æ³¢åŠ¨è°ƒæ•´ä»·å€¼", analyzer.calculate_vol_adjusted_value)
    analyzer.calculate_synthetic_factor("é‡ä»·èƒŒç¦»", analyzer.calculate_volume_price_divergence)
    analyzer.calculate_synthetic_factor("ç›ˆåˆ©å¢é•¿", analyzer.calculate_profitability_growth)
    analyzer.calculate_synthetic_factor("åŠ¨é‡æ’åå› å­ I", analyzer.calculate_Momentum_Ranking_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·æ ¼å˜åŠ¨é€Ÿç‡å› å­ I", analyzer.calculate_Price_Rate_of_Change_Factor_I)
    analyzer.calculate_synthetic_factor("ç´¯ç§¯ä»·æ ¼å˜åŒ–å› å­ I", analyzer.calculate_Cumulative_Price_Change_Factor_I)
    analyzer.calculate_synthetic_factor("å¤šæœŸåŠ¨é‡å åŠ å› å­ I", analyzer.calculate_Multi_period_Momentum_Overlay_Factor_I)
    analyzer.calculate_synthetic_factor("é«˜ä½ä»·åŠ¨é‡å› å­ I", analyzer.calculate_High_Low_Price_Momentum_Factor_I)
    analyzer.calculate_synthetic_factor("é•¿æœŸä»·æ ¼æ°´å¹³å› å­ I", analyzer.calculate_Long_term_Price_Level_Factor_I)
    analyzer.calculate_synthetic_factor("åŠ¨é‡æŒ‡æ ‡å› å­ I", analyzer.calculate_Momentum_Indicator_Factor_I)

    analyzer.calculate_synthetic_factor("ä»·é‡åŒæ­¥æ€§å› å­ I", analyzer.calculate_Price_Volume_Synchronization_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·é‡å¼ºåº¦å› å­ I", analyzer.calculate_Price_Volume_Intensity_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·é‡æ¶¨å¹…ååŒå› å­ I", analyzer.calculate_Price_Volume_Gain_Synergy_Factor_I)
    analyzer.calculate_synthetic_factor("ç›¸å¯¹å¼ºåº¦æˆäº¤é‡å› å­ I", analyzer.calculate_Relative_Strength_Volume_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·é‡å¼ºåº¦å› å­", analyzer.calculate_Price_Volume_Intensity_Factor)
    analyzer.calculate_synthetic_factor("å¤šæœŸä»·é‡åŠ¨é‡å› å­ I",
                                        analyzer.calculate_Multi_period_Price_Volume_Momentum_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·é‡ç»å¯¹åŒæ­¥å› å­ I",
                                        analyzer.calculate_Price_Volume_Absolute_Synchronization_Factor_I)
    analyzer.calculate_synthetic_factor("ç»å¯¹ä»·é‡å˜åŒ–å› å­ I", analyzer.calculate_Absolute_Price_Volume_Change_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·é‡å˜åŠ¨å…³ç³»å› å­ I",
                                        analyzer.calculate_Price_Volume_Movement_Relationship_Factor_I)
    analyzer.calculate_synthetic_factor("çŸ­æœŸä»·é‡äº’åŠ¨å› å­ I",
                                        analyzer.calculate_Short_term_Price_Volume_Interaction_Factor_I)

    analyzer.calculate_synthetic_factor("é‡ä»·èƒŒç¦»å› å­", analyzer.calculate_Price_Volume_Divergence_Factor)
    analyzer.calculate_synthetic_factor("è´Ÿä»·é‡ç›¸å…³æ€§å› å­ I",
                                        analyzer.calculate_Negative_Price_Volume_Correlation_Factor_I)
    analyzer.calculate_synthetic_factor("å¸‚åœºåè½¬æ•æ‰å› å­ I", analyzer.calculate_Market_Reversal_Capture_Factor_I)
    analyzer.calculate_synthetic_factor("å¸‚åœºåè½¬æ—¶æœºå› å­ I", analyzer.calculate_Market_Reversal_Timing_Factor_I)
    analyzer.calculate_synthetic_factor("åè½¬æ½œåŠ›è¯„ä¼°å› å­ I", analyzer.calculate_Reversal_Potential_Assessment_Factor_I)
    analyzer.calculate_synthetic_factor("å›è°ƒé£é™©è¯†åˆ«å› å­ I", analyzer.calculate_Pullback_Risk_Identification_Factor_I)
    analyzer.calculate_synthetic_factor("åè½¬ä¿¡å·å¼ºåº¦å› å­ I", analyzer.calculate_Reversal_Signal_Strength_Factor_I)
    analyzer.calculate_synthetic_factor("è¶‹åŠ¿åè½¬é¢„è­¦å› å­ I", analyzer.calculate_Trend_Reversal_Warning_Factor_I)

    analyzer.calculate_synthetic_factor("è‚¡ä»·æ³¢åŠ¨æ€§ä¸æˆäº¤é‡å˜åŒ–å› å­",
                                        analyzer.calculate_Stock_Volatility_and_Volume_Change_Factor)
    analyzer.calculate_synthetic_factor("ä»·æ ¼æ–¹å·®å› å­ I", analyzer.calculate_Price_Variance_Factor_I)
    analyzer.calculate_synthetic_factor("å¸‚åœºä¸ç¡®å®šæ€§åº¦é‡å› å­ I",
                                        analyzer.calculate_Market_Uncertainty_Measurement_Factor_I)
    analyzer.calculate_synthetic_factor("å¸ƒæ—å¸¦ä¸Šè½¨å› å­ I", analyzer.calculate_Bollinger_Upper_Band_Factor_I)
    analyzer.calculate_synthetic_factor("å¸ƒæ—å¸¦ä¸‹è½¨å› å­ I", analyzer.calculate_Bollinger_Lower_Band_Factor_I)
    analyzer.calculate_synthetic_factor("çŸ­æœŸæ³¢åŠ¨æˆäº¤é‡å› å­ I",
                                        analyzer.calculate_Short_term_Volatility_Volume_Factor_I)
    analyzer.calculate_synthetic_factor("é•¿æœŸæ³¢åŠ¨æˆäº¤é‡å› å­ I", analyzer.calculate_Long_term_Volatility_Volume_Factor_I)
    analyzer.calculate_synthetic_factor("æ³¢åŠ¨æˆäº¤é‡å› å­ I", analyzer.calculate_Volatility_Volume_Factor_I)
    analyzer.calculate_synthetic_factor("æ³¢åŠ¨ç‡æˆäº¤é‡ååŒå› å­ I", analyzer.calculate_Volatility_Volume_Synergy_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·æ ¼ååº¦å› å­ I", analyzer.calculate_Price_Skewness_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·æ ¼å³°åº¦å› å­ I", analyzer.calculate_Price_Kurtosis_Factor_I)
    analyzer.calculate_synthetic_factor("å¤æ™®æ¯”ç‡å› å­ I", analyzer.calculate_Sharpe_Ratio_Factor_I)
    analyzer.calculate_synthetic_factor("æ³¢åŠ¨é£é™©è¯„ä¼°å› å­ I", analyzer.calculate_Volatility_Risk_Assessment_Factor_I)
    analyzer.calculate_synthetic_factor("é£é™©å›æŠ¥å¹³è¡¡å› å­ I", analyzer.calculate_Risk_Return_Balance_Factor_I)
    analyzer.calculate_synthetic_factor("æ ‡å‡†å·®åç¦»åº¦å› å­ I", analyzer.calculate_Standard_Deviation_Deviation_Factor_I)

    analyzer.calculate_synthetic_factor("æˆäº¤é‡åŠ¨é‡å› å­ I", analyzer.calculate_Volume_Momentum_Factor_I)
    analyzer.calculate_synthetic_factor("é«˜æˆäº¤é‡ç­›é€‰å› å­ I", analyzer.calculate_High_Volume_Screening_Factor_I)
    analyzer.calculate_synthetic_factor("æˆäº¤é‡å˜åŠ¨é€Ÿç‡å› å­ I", analyzer.calculate_Volume_Rate_of_Change_Factor_I)
    analyzer.calculate_synthetic_factor("æ—¶é—´æˆäº¤é‡å‡çº¿å› å­ I", analyzer.calculate_Time_Volume_Moving_Average_Factor_I)
    analyzer.calculate_synthetic_factor("æ—¶é—´æˆäº¤é‡å‡çº¿å› å­ II",
                                        analyzer.calculate_Time_Volume_Moving_Average_Factor_II)
    analyzer.calculate_synthetic_factor("æˆäº¤é‡æŒ‡æ•°å‡çº¿å› å­ I",
                                        analyzer.calculate_Volume_Exponential_Moving_Average_Factor_I)
    analyzer.calculate_synthetic_factor("æˆäº¤é‡æŒ‡æ•°å‡çº¿å› å­ II",
                                        analyzer.calculate_Volume_Exponential_Moving_Average_Factor_II)
    analyzer.calculate_synthetic_factor("å¹³å‡æˆäº¤é‡å› å­ I", analyzer.calculate_Average_Volume_Factor_I)
    analyzer.calculate_synthetic_factor("åŠ¨æ€æˆäº¤é‡æ¯”ç‡å› å­ I", analyzer.calculate_Dynamic_Volume_Ratio_Factor_I)
    analyzer.calculate_synthetic_factor("æˆäº¤é‡å·®å€¼å› å­ I", analyzer.calculate_Volume_Difference_Factor_I)
    analyzer.calculate_synthetic_factor("MACD å› å­ I", analyzer.calculate_MACD_Factor_I)
    analyzer.calculate_synthetic_factor("å•†å“é€šé“æŒ‡æ•°å› å­ I", analyzer.calculate_Commodity_Channel_Index_Factor_I)
    analyzer.calculate_synthetic_factor("è¶…ä¹°è¶…å–æŒ‡æ ‡å› å­ I", analyzer.calculate_Overbought_Oversold_Indicator_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·æ ¼åç¦»å› å­ I", analyzer.calculate_Price_Bias_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·æ ¼åç¦»å› å­ II", analyzer.calculate_Price_Bias_Factor_II)
    analyzer.calculate_synthetic_factor("ä»·æ ¼åç¦»å› å­ III", analyzer.calculate_Price_Bias_Factor_III)
    analyzer.calculate_synthetic_factor("ä»·æ ¼åç¦»å› å­ IV", analyzer.calculate_Price_Bias_Factor_IV)
    analyzer.calculate_synthetic_factor("æŒ‡æ•°ç§»åŠ¨å¹³å‡å› å­ I", analyzer.calculate_Exponential_Moving_Average_Factor_I)
    analyzer.calculate_synthetic_factor("å‘¨æ”¶ç›˜æ’åå› å­ I", analyzer.calculate_Weekly_Close_Rank_Factor_I)
    analyzer.calculate_synthetic_factor("ä»·æ ¼åŒºé—´åˆ†æå› å­ I", analyzer.calculate_Price_Range_Analysis_Factor_I)
    analyzer.calculate_synthetic_factor("æ—¶é—´åºåˆ—æ’åå› å­ I", analyzer.calculate_Time_Series_Ranking_Factor_I)
    analyzer.calculate_synthetic_factor("ç›¸å¯¹æ³¢åŠ¨æ€§å› å­ I", analyzer.calculate_Relative_Volatility_Factor_I)

    print("\n--- 3. æ‰§è¡Œæ‰€æœ‰å› å­åˆ†æå¹¶è¾“å‡ºç»“æœ ---")

    # è·å–æ‰€æœ‰å› å­åç§°çš„åˆ—è¡¨
    all_factor_names = list(analyzer.synthetic_factors.keys())

    # å¾ªç¯éå†æ‰€æœ‰å› å­è¿›è¡Œåˆ†æ
    for factor_name in all_factor_names:
        # è®¾ç½®é»˜è®¤ plot=False
        should_plot = False

        # ç‰¹åˆ«å¤„ç†æ‚¨æŒ‡å®šéœ€è¦ç»˜å›¾çš„å› å­
        if factor_name == 'ä»·æ ¼ååº¦å› å­ I':
            should_plot = True

        print(f"  > æ­£åœ¨åˆ†æå› å­: {factor_name} (plot={should_plot})")

        # æ‰§è¡Œåˆ†æ
        analyzer.analyze_factor(factor_name, plot=should_plot)

    print("\nğŸ‰ æ‰€æœ‰å› å­çš„è®¡ç®—å’Œåˆ†æå·²å®Œæˆï¼åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° Excelã€‚")

    global all_factors

if __name__ == "__main__":
    main()


