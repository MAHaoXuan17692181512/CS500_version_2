import pandas as pd
import numpy as np  # <<< æ–°å¢ï¼šå¼•å…¥ numpy
import os
import re
from datetime import datetime
from numpy.linalg import inv, LinAlgError  # <<< å¼•å…¥æ±‚é€†å‡½æ•°
from numpy.linalg import pinv, LinAlgError
# ----------------- ã€è¯·ä¿®æ”¹ä»¥ä¸‹è·¯å¾„ã€‘ -----------------
# æ”¶ç›Šç‡æ•°æ®ï¼ˆQå’Œå…ˆéªŒæ”¶ç›Šï¼‰çš„æ¥æºæ–‡ä»¶è·¯å¾„
returns_file_path = r"C:\Users\cufet\Desktop\filtered_updated_returns.xlsx"
# åæ–¹å·®çŸ©é˜µæ–‡ä»¶å¤¹è·¯å¾„
covariance_folder_path = r"C:\Users\cufet\Desktop\åæ–¹å·®"
# æœ€ç»ˆè¾“å‡º Excel æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
output_combined_file_path = r'C:\Users\cufet\Desktop\combined_bayesian_results.xlsx'
# ------------------------------------------------------

# >>>>>> Black-Litterman æ¨¡å‹å‚æ•°è®¾ç½® <<<<<<
TAU = 0.025  # æƒé‡ä¸ç¡®å®šæ€§å› å­ (æ ‡é‡ï¼Œéœ€æ ¹æ®æ¨¡å‹è®¾å®š)

# è¾…åŠ©å‡½æ•°ï¼šä»åæ–¹å·®æ–‡ä»¶å/Sheetåä¸­æå–æˆªæ­¢æ—¥æœŸï¼ˆ'to_'åé¢çš„æ—¥æœŸï¼‰
def extract_end_date_from_name(name):
    """ä» YYYY-MM-DD_to_YYYY-MM-DD æ ¼å¼çš„å­—ç¬¦ä¸²ä¸­æå–ç¬¬äºŒä¸ªæ—¥æœŸã€‚"""
    match = re.search(r'to[_\s](\d{4}-\d{2}-\d{2})', str(name), re.IGNORECASE)
    if match: return match.group(1)
    return None


# --- 1. è¯»å–å¹¶å¤„ç†åæ–¹å·®æ•°æ® (ä¿æŒä¸å˜ï¼Œå·²ä¿®æ­£æ–‡ä»¶åé—®é¢˜) ---
# covariance_data = {}
# print("--- 1. æ­£åœ¨è¯»å–å’Œå¤„ç†åæ–¹å·®æ•°æ® ---")
# try:
#     for filename in os.listdir(covariance_folder_path):
#         if filename.endswith(('.xls', '.xlsx')):
#             full_path = os.path.join(covariance_folder_path, filename)
#             xls = pd.ExcelFile(full_path)
#
#             if not xls.sheet_names:
#                 print(f"è­¦å‘Š: æ–‡ä»¶ {filename} ä¸­ä¸åŒ…å«ä»»ä½• Sheetï¼Œè·³è¿‡ã€‚")
#                 continue
#
#             sheet_name_to_read = xls.sheet_names[0]
#             date_str = extract_end_date_from_name(sheet_name_to_read)
#
#             if not date_str:
#                 print(f"è­¦å‘Š: æ–‡ä»¶ {filename} çš„ç¬¬ä¸€ä¸ª Sheet åç§° '{sheet_name_to_read}' æ ¼å¼ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡ã€‚")
#                 continue
#
#             df_cov = pd.read_excel(xls, sheet_name=sheet_name_to_read, index_col=0)
#
#             df_cov.columns = df_cov.columns.astype(str).str.strip()
#             df_cov.index = df_cov.index.astype(str).str.strip()
#
#             covariance_data[date_str] = df_cov
#             print(f"  - æˆåŠŸè¯»å–åæ–¹å·®æ•°æ®ï¼Œæ—¥æœŸ: {date_str}ï¼Œæ–‡ä»¶: {filename}ï¼Œç»´åº¦: {df_cov.shape}")
#
# except Exception as e:
#     print(f"è¯»å–åæ–¹å·®æ•°æ®æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
#     exit()
#
# if not covariance_data:
#     print("é”™è¯¯ï¼šæœªæˆåŠŸè¯»å–ä»»ä½•åæ–¹å·®æ•°æ®ã€‚ç¨‹åºé€€å‡ºã€‚")
#     exit()
# --- 1. è¯»å–å¹¶å¤„ç†åæ–¹å·®æ•°æ® (å·²ä¿®æ­£ä¸ºè¯»å–æ‰€æœ‰ Sheet) ---
covariance_data = {}
print("--- 1. æ­£åœ¨è¯»å–å’Œå¤„ç†åæ–¹å·®æ•°æ® ---")
try:
    for filename in os.listdir(covariance_folder_path):
        if filename.endswith(('.xls', '.xlsx')):
            full_path = os.path.join(covariance_folder_path, filename)

            # æ‰“å¼€ Excel æ–‡ä»¶
            xls = pd.ExcelFile(full_path)

            if not xls.sheet_names:
                print(f"è­¦å‘Š: æ–‡ä»¶ {filename} ä¸­ä¸åŒ…å«ä»»ä½• Sheetï¼Œè·³è¿‡ã€‚")
                continue

            # >>>>>> å…³é”®ä¿®æ”¹ï¼šéå†æ–‡ä»¶ä¸­çš„æ‰€æœ‰ Sheet <<<<<<
            for sheet_name_to_read in xls.sheet_names:

                # ä» Sheet åç§°ä¸­æå–æˆªæ­¢æ—¥æœŸä½œä¸º Key
                date_str = extract_end_date_from_name(sheet_name_to_read)

                if not date_str:
                    print(f"è­¦å‘Š: æ–‡ä»¶ {filename} ä¸­çš„ Sheet åç§° '{sheet_name_to_read}' æ ¼å¼ä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡æ­¤ Sheetã€‚")
                    continue

                # è¯»å–åæ–¹å·®çŸ©é˜µ
                df_cov = pd.read_excel(xls, sheet_name=sheet_name_to_read, index_col=0)

                df_cov.columns = df_cov.columns.astype(str).str.strip()
                df_cov.index = df_cov.index.astype(str).str.strip()

                # å­˜å‚¨æ•°æ®
                if date_str in covariance_data:
                    # å¯é€‰ï¼šå¦‚æœä¸åŒæ–‡ä»¶æˆ– Sheet åŒ…å«ç›¸åŒæ—¥æœŸï¼Œå‘å‡ºè­¦å‘Š
                    print(
                        f"è­¦å‘Š: æ—¥æœŸ {date_str} çš„åæ–¹å·®æ•°æ®å·²å­˜åœ¨ï¼Œå°†è¢«å½“å‰æ–‡ä»¶ {filename} çš„ Sheet '{sheet_name_to_read}' è¦†ç›–ã€‚")

                covariance_data[date_str] = df_cov
                print(
                    f"  - æˆåŠŸè¯»å–åæ–¹å·®æ•°æ®ï¼Œæ—¥æœŸ: {date_str}ï¼Œæ–‡ä»¶: {filename}ï¼ŒSheet: {sheet_name_to_read}ï¼Œç»´åº¦: {df_cov.shape}")
            # >>>>>> å…³é”®ä¿®æ”¹ç»“æŸ <<<<<<

except Exception as e:
    print(f"è¯»å–åæ–¹å·®æ•°æ®æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
    exit()

if not covariance_data:
    print("é”™è¯¯ï¼šæœªæˆåŠŸè¯»å–ä»»ä½•åæ–¹å·®æ•°æ®ã€‚ç¨‹åºé€€å‡ºã€‚")
    exit()
# --- 2. è¯»å– Q å’Œ å…ˆéªŒæ”¶ç›Šæ•°æ® (ä¿æŒä¸å˜) ---
returns_data = {}
print("\n--- 2. æ­£åœ¨è¯»å– Q å’Œå…ˆéªŒæ”¶ç›Šæ•°æ® ---")
try:
    xls = pd.ExcelFile(returns_file_path)
    for sheet_name in xls.sheet_names:
        date_str = sheet_name.strip()
        try:
            datetime.strptime(date_str, '%Y-%m-%d')
        except ValueError:
            print(f"è­¦å‘Š: æ”¶ç›Šæ–‡ä»¶ä¸­çš„ Sheet åç§° '{sheet_name}' ä¸æ˜¯æœ‰æ•ˆçš„æ—¥æœŸæ ¼å¼ï¼Œè·³è¿‡ã€‚")
            continue

        df_returns = pd.read_excel(xls, sheet_name=sheet_name, index_col=0)
        df_returns.index.name = 'è‚¡ç¥¨ä»£ç '

        if 'Q' in df_returns.columns and 'å…ˆéªŒæ”¶ç›Š' in df_returns.columns:
            returns_data[date_str] = df_returns[['Q', 'å…ˆéªŒæ”¶ç›Š']]
            print(f"  - æˆåŠŸè¯»å–æ”¶ç›Šæ•°æ®ï¼Œæ—¥æœŸ: {date_str}ï¼Œè‚¡ç¥¨æ•°: {len(df_returns)}")
        else:
            print(f"è­¦å‘Š: Sheet '{sheet_name}' ç¼ºå°‘ 'Q' æˆ– 'å…ˆéªŒæ”¶ç›Š' åˆ—ï¼Œè·³è¿‡ã€‚")

except FileNotFoundError:
    print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°æ”¶ç›Šæ–‡ä»¶: {returns_file_path}ã€‚è¯·æ£€æŸ¥è·¯å¾„ã€‚")
    exit()
except Exception as e:
    print(f"è¯»å–æ”¶ç›Šæ•°æ®æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
    exit()

if not returns_data:
    print("é”™è¯¯ï¼šæœªæˆåŠŸè¯»å–ä»»ä½•æ”¶ç›Šæ•°æ®ã€‚ç¨‹åºé€€å‡ºã€‚")
    exit()


# ----------------- ã€è¯·ä¿®æ”¹ä»¥ä¸‹è·¯å¾„ã€‘ -----------------
# ... (è·¯å¾„éƒ¨åˆ†ä¿æŒä¸å˜) ...
returns_file_path = r"C:\Users\cufet\Desktop\filtered_updated_returns.xlsx"
covariance_folder_path = r"C:\Users\cufet\Desktop\åæ–¹å·®"
output_combined_file_path = r'C:\Users\cufet\Desktop\BLåéªŒç»“æœ.xlsx'
# ------------------------------------------------------

# >>>>>> Black-Litterman æ¨¡å‹å‚æ•°è®¾ç½® <<<<<<
TAU = 0.025  # æƒé‡ä¸ç¡®å®šæ€§å› å­ (æ ‡é‡ï¼Œéœ€æ ¹æ®æ¨¡å‹è®¾å®š)
# ------------------------------------------------------

# ... (è¾…åŠ©å‡½æ•°ã€ç¬¬ 1 æ­¥å’Œç¬¬ 2 æ­¥ä»£ç ä¿æŒä¸å˜) ...

# --- 3. æ•´åˆæ•°æ®ã€æ‰§è¡Œ Black-Litterman è¿ç®—å¹¶è¾“å‡º Excel ---
print("\n--- 3. æ­£åœ¨æ•´åˆæ•°æ®ã€æ‰§è¡Œ Black-Litterman è¿ç®—å¹¶è¾“å‡º Excel ---")

common_dates = sorted(list(set(returns_data.keys()) & set(covariance_data.keys())))

# ... (é”™è¯¯æ£€æŸ¥ä»£ç ä¿æŒä¸å˜) ...
with pd.ExcelWriter(output_combined_file_path, engine='xlsxwriter') as writer:
    for date_str in common_dates:
        df_returns = returns_data[date_str]
        df_cov = covariance_data[date_str]

        # --- æ•°æ®å¯¹é½ ---
        stock_index_returns = df_returns.index.tolist()
        stock_index_cov = df_cov.index.tolist()
        common_stocks = sorted(list(set(stock_index_returns) & set(stock_index_cov)))

        if not common_stocks:
            print(f"è­¦å‘Š: æ—¥æœŸ {date_str} çš„æ”¶ç›Šå’Œåæ–¹å·®æ•°æ®ä¸­æ²¡æœ‰å…±åŒçš„è‚¡ç¥¨ä»£ç ï¼Œè·³è¿‡æ­¤æ—¥æœŸã€‚")
            continue

        # å¯¹é½æ”¶ç›Šæ•°æ®
        df_returns_aligned = df_returns.reindex(common_stocks)
        # å¯¹é½åæ–¹å·®çŸ©é˜µ
        df_cov_aligned = df_cov.reindex(index=common_stocks, columns=common_stocks)

        # 1. è½¬æ¢ä¸º Numpy æ•°ç»„è¿›è¡ŒçŸ©é˜µè¿ç®—
        Sigma = df_cov_aligned.values
        Pi = df_returns_aligned['å…ˆéªŒæ”¶ç›Š'].values.reshape(-1, 1)  # N x 1 å‘é‡ (å…ˆéªŒå‡å€¼)
        Q = df_returns_aligned['Q'].values.reshape(-1, 1)  # N x 1 å‘é‡ (è§‚ç‚¹æ”¶ç›Š)
        N = len(common_stocks)

        # 2. æ„é€  P å’Œ Omega
        # P çŸ©é˜µ (å‡è®¾ï¼šN x N å•ä½çŸ©é˜µï¼Œå³æ¯ä¸ªè‚¡ç¥¨éƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹è§‚ç‚¹)
        P = np.identity(N)

        try:
            # Sigma é€†çŸ©é˜µ (æ”¹ä¸ºä¼ªé€†)
            Sigma_inv = pinv(Sigma)

            # Omega çŸ©é˜µ: ä½¿ç”¨ç®€åŒ–å…¬å¼ Omega = diag(P * (tau * Sigma) * P^T)
            Omega_diag_elements = np.diag(P @ (TAU * Sigma) @ P.T)
            Omega = np.diag(Omega_diag_elements)

            # Omega é€†çŸ©é˜µ (æ”¹ä¸ºä¼ªé€†)
            Omega_inv = pinv(Omega)

            # --- æ‰§è¡Œå®Œæ•´çš„ Black-Litterman å…¬å¼ ---

            # æ ¸å¿ƒé¡¹ A = (tau * Sigma^-1 + P^T * Omega^-1 * P)^-1
            # è¿™ä¸€é¡¹å°±æ˜¯åéªŒåæ–¹å·® Sigma_p
            A_matrix_inv = (TAU * Sigma_inv) + P.T @ Omega_inv @ P
            Sigma_p_np = pinv(A_matrix_inv)  # åéªŒåæ–¹å·®

            # ä½¿ç”¨æ‚¨å®šä¹‰çš„æœ€ç»ˆåæ–¹å·®çŸ©é˜µ
            Sigma_p_np_end = Sigma_p_np + Sigma

            # æ ¸å¿ƒé¡¹ B = (tau * Sigma^-1) * Pi + P^T * Omega^-1 * Q
            B_vector = (TAU * Sigma_inv) @ Pi + P.T @ Omega_inv @ Q

            # åéªŒå‡å€¼ Mu_bar = Sigma_p * B
            Mu_bar_np = Sigma_p_np @ B_vector

            # 3. è½¬æ¢ä¸º DataFrame å‡†å¤‡è¾“å‡º
            df_mu_bar = pd.DataFrame(Mu_bar_np, index=common_stocks, columns=['åéªŒæ”¶ç›Š_MuBar'])
            # df_Sigma_p ç”¨äºè¾“å‡ºæœ€ç»ˆçš„åæ–¹å·®çŸ©é˜µ
            df_Sigma_p = pd.DataFrame(Sigma_p_np_end, index=common_stocks, columns=common_stocks)

            print(f"  - æ—¥æœŸ {date_str}: æˆåŠŸè®¡ç®— Black-Litterman åéªŒå‡å€¼å’Œåæ–¹å·®ã€‚")

        except LinAlgError:
            # å°½ç®¡ä½¿ç”¨äº† pinvï¼Œä½†å¦‚æœè¾“å…¥çŸ©é˜µæœ‰ä¸¥é‡çš„æ•°å€¼é—®é¢˜ï¼Œä»ç„¶å¯èƒ½å¤±è´¥
            print(f"é”™è¯¯: æ—¥æœŸ {date_str} çš„çŸ©é˜µè¿ç®—å¤±è´¥ (å¯èƒ½ç”±äºä¸¥é‡æ•°å€¼é—®é¢˜)ï¼Œè·³è¿‡ã€‚")
            continue

        # --- æ•°æ®è¾“å‡º ---

        # Sheet 1: Black-Litterman ç»“æœ (Mu_bar, Q, å…ˆéªŒæ”¶ç›Š)
        sheet_name_results = f"{date_str}_Results"

        # 1. è¾“å‡ºåéªŒæ”¶ç›Šå‡å€¼ (Mu_bar)
        df_mu_bar.to_excel(writer, sheet_name=sheet_name_results, startrow=0, startcol=0, float_format='%.8f')

        # 2. è¾“å‡ºåŸå§‹çš„ Q å’Œå…ˆéªŒæ”¶ç›Šï¼Œæ”¾åœ¨å³ä¾§
        df_returns_aligned[['Q', 'å…ˆéªŒæ”¶ç›Š']].to_excel(writer, sheet_name=sheet_name_results, startrow=0,
                                                       startcol=df_mu_bar.shape[1] + 2, float_format='%.8f')

        print(f"  - å®Œæˆç»“æœ Sheet: {sheet_name_results}")

        # >>>>>> æœ€å°åŒ–ä¿®æ”¹ 1 & 2ï¼šå•ç‹¬è¾“å‡ºåæ–¹å·®çŸ©é˜µ <<<<<<

        # Sheet 2: åæ–¹å·®çŸ©é˜µ
        sheet_name_cov = date_str  # å‘½åä¸ºæ—¥æœŸ

        # è¾“å‡ºåæ–¹å·®çŸ©é˜µ
        df_Sigma_p.to_excel(writer, sheet_name=sheet_name_cov, startrow=0, startcol=0, float_format='%.8f')

        print(f"  - å®Œæˆåæ–¹å·® Sheet: {sheet_name_cov}")

        # ç§»é™¤åŸæœ‰çš„åœ¨ _Results Sheet ä¸­è¾“å‡ºåæ–¹å·®çš„å…¨éƒ¨ä»£ç 
        # start_row_cov = df_mu_bar.shape[0] + 3
        # workbook = writer.book
        # worksheet = writer.sheets[sheet_name]
        # try:
        #     worksheet.write(start_row_cov - 2, 0, 'åéªŒåæ–¹å·® Sigma_p:')
        # except:
        #     pass
        # df_Sigma_p.to_excel(writer, sheet_name=sheet_name, startrow=start_row_cov, startcol=0, float_format='%.8f')
        # >>>>>> æœ€å°åŒ–ä¿®æ”¹ç»“æŸ <<<<<<

print("\n" + "=" * 50)
print(f"ğŸ‰ æœ€ç»ˆ Black-Litterman ç»“æœæ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_combined_file_path}")
print(f"æ€»å…±ç”Ÿæˆäº† {2 * len(common_dates)} ä¸ª Sheet (æ¯ä¸ªæ—¥æœŸä¸¤ä¸ª Sheet)ã€‚")
print("=" * 50)

# æ˜ç¡®ä¿®æ”¹äº†å“ªé‡Œï¼š
# 1. å°†åŸæœ‰çš„æ•°æ®è¾“å‡ºé€»è¾‘åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«å¯¹åº”ä¸¤ä¸ª Sheetã€‚
# 2. ç¬¬ä¸€ä¸ª Sheet å‘½åä¸º f"{date_str}_Results" (åŒ…å« Mu_bar, Q, å…ˆéªŒæ”¶ç›Š)ã€‚
# 3. æ–°å¢ç¬¬äºŒä¸ª Sheetï¼Œå‘½åä¸º date_str (åŒ…å« df_Sigma_pï¼Œå³æœ€ç»ˆåéªŒåæ–¹å·®)ã€‚
# 4. ç§»é™¤äº†åœ¨ f"{date_str}_Results" Sheet ä¸­è¾“å‡ºåæ–¹å·®çŸ©é˜µåŠå…¶æ ‡é¢˜çš„ä»£ç ã€‚
