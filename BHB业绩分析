import pandas as pd
import numpy as np
import warnings

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

# --- å‡è®¾æ–‡ä»¶è·¯å¾„å’ŒSheetåç§° ---
file_path = r"C:\Users\cufet\Desktop\æµ‹è¯•é›†\æœ€ç»ˆåˆå¹¶æƒé‡_70_30.xlsx"

# å‡è®¾æ‚¨çš„æ–‡ä»¶åŒ…å«ä¸‰ä¸ªå·¥ä½œè¡¨
SHEET_STRATEGY_WEIGHT = 'åŸºç¡€æƒé‡'  # ç­–ç•¥æŒä»“é‡‘é¢/å¸‚å€¼
SHEET_RETURN = 'èµ„äº§æ”¶ç›Š'  # èµ„äº§æ”¶ç›Šç‡
SHEET_BENCHMARK_WEIGHT = 'èµ„äº§æƒé‡'  # åŸºå‡†æŒä»“é‡‘é¢/å¸‚å€¼

try:
    # ç­–ç•¥æŒä»“æ•°æ®
    data_strategy_holding = pd.read_excel(file_path, sheet_name=SHEET_STRATEGY_WEIGHT)
    # èµ„äº§æ”¶ç›Šç‡
    data_return = pd.read_excel(file_path, sheet_name=SHEET_RETURN)
    # åŸºå‡†æŒä»“æ•°æ®
    data_benchmark_holding = pd.read_excel(file_path, sheet_name=SHEET_BENCHMARK_WEIGHT)

except FileNotFoundError:
    print("ã€è­¦å‘Šã€‘æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ­£åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")


# 1. é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–åˆ—å
code_col = data_strategy_holding.columns[0]
industry_col = data_strategy_holding.columns[1]

data_strategy_holding = data_strategy_holding.rename(columns={code_col: 'ä»£ç ', industry_col: 'äºŒçº§è¡Œä¸š'})
data_return = data_return.rename(columns={code_col: 'ä»£ç ', industry_col: 'äºŒçº§è¡Œä¸š'})
data_benchmark_holding = data_benchmark_holding.rename(columns={code_col: 'ä»£ç ', industry_col: 'äºŒçº§è¡Œä¸š'})

# 2. ç¡®å®šæ—¥æœŸåˆ—
date_columns = data_strategy_holding.columns[2:]

# å­˜å‚¨å…¨å±€æ±‡æ€»ç»“æœ
results = []
# å­˜å‚¨æ‰€æœ‰æœŸã€æ‰€æœ‰è¡Œä¸šçš„è¯¦ç»†æ•°æ®ï¼ˆç”¨äºåç»­æ±‡æ€»å’Œå›¾è¡¨ï¼‰
all_industry_attribution_data = []

# -----------------------------------------------------------
# I. æ ¸å¿ƒ Brinson å½’å› å¾ªç¯ï¼šè®¡ç®—å…¨å±€ç»“æœå¹¶æ”¶é›†è¡Œä¸šæ•°æ®
# -----------------------------------------------------------
for date_col in date_columns:
    print(f"\nProcessing date: {date_col}")

    # 3. æ•°æ®åˆå¹¶
    df_hp = data_strategy_holding[['ä»£ç ', 'äºŒçº§è¡Œä¸š', date_col]].rename(columns={date_col: 'H_P'})
    df_rp = data_return[['ä»£ç ', date_col]].rename(columns={date_col: 'R_P'})
    df_hb = data_benchmark_holding[['ä»£ç ', date_col]].rename(columns={date_col: 'H_B'})

    current_data = pd.merge(df_hp, df_rp, on='ä»£ç ', how='inner')
    current_data = pd.merge(current_data, df_hb, on='ä»£ç ', how='inner')

    # 4. æ¸…ç†å’Œè®¡ç®— Wp, Wb
    current_data.dropna(subset=['H_P', 'R_P', 'H_B'], inplace=True)

    total_h_p = current_data['H_P'].sum()
    total_h_b = current_data['H_B'].sum()

    if total_h_p == 0 or total_h_b == 0:
        print(f"Skipping date {date_col}: Total holding is zero.")
        continue

    current_data['W_P'] = current_data['H_P'] / total_h_p
    current_data['W_B'] = current_data['H_B'] / total_h_b

    # 5. è®¡ç®—è¡Œä¸šçº§æŒ‡æ ‡ (w_P, w_B, r_P, r_B)
    industry_weights = current_data.groupby('äºŒçº§è¡Œä¸š')['W_P'].sum().reset_index(name='w_P')
    industry_weights_b = current_data.groupby('äºŒçº§è¡Œä¸š')['W_B'].sum().reset_index(name='w_B')

    industry_returns_P = current_data.groupby('äºŒçº§è¡Œä¸š').apply(
        lambda x: (x['W_P'] * x['R_P']).sum() / x['W_P'].sum() if x['W_P'].sum() != 0 else np.nan
    ).reset_index(name='r_P').dropna()

    industry_returns_B = current_data.groupby('äºŒçº§è¡Œä¸š').apply(
        lambda x: (x['W_B'] * x['R_P']).sum() / x['W_B'].sum() if x['W_B'].sum() != 0 else np.nan
    ).reset_index(name='r_B').dropna()

    # 6. åˆå¹¶è¡Œä¸šçº§æ•°æ®
    data_analysis = pd.merge(industry_weights, industry_weights_b, on='äºŒçº§è¡Œä¸š', how='inner')
    data_analysis = pd.merge(data_analysis, industry_returns_P, on='äºŒçº§è¡Œä¸š', how='inner')
    data_analysis = pd.merge(data_analysis, industry_returns_B, on='äºŒçº§è¡Œä¸š', how='inner')

    # 7. Brinson æ¨¡å‹åˆ†è§£ (è¡Œä¸šçº§)
    data_analysis['AR'] = (data_analysis['w_P'] - data_analysis['w_B']) * data_analysis['r_B']
    data_analysis['SR'] = (data_analysis['r_P'] - data_analysis['r_B']) * data_analysis['w_B']
    data_analysis['IR'] = (data_analysis['w_P'] - data_analysis['w_B']) * (data_analysis['r_P'] - data_analysis['r_B'])

    # 8. æ±‡æ€»è‡³å…¨å±€ç»“æœ (ç”¨äº results åˆ—è¡¨)
    R_P_total = (current_data['W_P'] * current_data['R_P']).sum()
    R_B_total = (current_data['W_B'] * current_data['R_P']).sum()
    Excess_Return = R_P_total - R_B_total
    Attribution_Sum = data_analysis['AR'].sum() + data_analysis['SR'].sum() + data_analysis['IR'].sum()

    results.append({
        'Date': date_col,
        'ç­–ç•¥æ”¶ç›Š(R_P)': R_P_total,
        'åŸºå‡†æ”¶ç›Š(R_B)': R_B_total,
        'è¶…é¢æ”¶ç›Š(R_P - R_B)': Excess_Return,
        'é…ç½®æ”¶ç›Š(AR)': data_analysis['AR'].sum(),
        'é€‰æ‹©æ”¶ç›Š(SR)': data_analysis['SR'].sum(),
        'äº¤äº’æ”¶ç›Š(IR)': data_analysis['IR'].sum(),
        'å½’å› æ€»å’Œ(AR+SR+IR)': Attribution_Sum,
        'å·®å¼‚(æ£€æŸ¥é¡¹)': Excess_Return - Attribution_Sum
    })

    # 9. å­˜å‚¨è¡Œä¸šæ•°æ® (ç”¨äºåç»­è®¡ç®—)
    data_analysis['Date'] = date_col
    data_analysis['ä¸»åŠ¨æƒé‡å·®'] = data_analysis['w_P'] - data_analysis['w_B']
    data_analysis['ä¸»åŠ¨æ”¶ç›Šå·®'] = data_analysis['r_P'] - data_analysis['r_B']
    all_industry_attribution_data.append(data_analysis)

# -----------------------------------------------------------
# II. ç»“æœè¾“å‡º - æ•´åˆæ‰€æœ‰éœ€æ±‚
# -----------------------------------------------------------

# å°†æ‰€æœ‰è¡Œä¸šçš„æ¯æ—¥æ•°æ®åˆå¹¶æˆä¸€ä¸ª DataFrame
if all_industry_attribution_data:
    final_industry_df = pd.concat(all_industry_attribution_data)
else:
    final_industry_df = pd.DataFrame()

# -----------------
# ç»“æœ 1: æŒ‰å¤©ï¼ˆä¸åˆ†è¡Œä¸šï¼‰çš„ Brinson å…¨å±€æ±‡æ€»æ•°æ®
# -----------------
results_df = pd.DataFrame(results)
output_file_path = r"C:\Users\cufet\Desktop\Output_1_Global_Daily_Brinson_Summary.xlsx"
results_df.to_excel(output_file_path, index=False)
print(f"\nâœ… 1. å…¨å±€æ¯æ—¥ Brinson æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³: {output_file_path}")

# -----------------
# ç»“æœ 2 & 3: æŒ‰è¡Œä¸šåˆ†æœŸå’Œæ€»è®¡çš„å›¾è¡¨æ•°æ®
# -----------------
if not final_industry_df.empty:

    # 2. æŒ‰è¡Œä¸šåˆ†æœŸçš„å›¾è¡¨æ•°æ® (äº¤äº’æ”¶ç›Šã€ä¸»åŠ¨æƒé‡å·®ã€ä¸»åŠ¨æ”¶ç›Šå·®)
    chart_data_daily = final_industry_df[['Date', 'äºŒçº§è¡Œä¸š', 'IR', 'ä¸»åŠ¨æƒé‡å·®', 'ä¸»åŠ¨æ”¶ç›Šå·®']].copy()
    output_chart_data_path = r"C:\Users\cufet\Desktop\Output_2_Industry_Daily_Chart_Data.xlsx"
    chart_data_daily.to_excel(output_chart_data_path, index=False)
    print(f"âœ… 2. è¡Œä¸šæ¯æ—¥å›¾è¡¨æ•°æ®ï¼ˆIR, ä¸»åŠ¨å·®é¢ï¼‰å·²ä¿å­˜è‡³: {output_chart_data_path}")

    # 3. æŒ‰è¡Œä¸šæ±‡æ€»çš„æ€»è®¡äº¤äº’æ”¶ç›Šã€ä¸»åŠ¨æ”¶ç›Šå·®ã€ä¸»åŠ¨æƒé‡å·®
    industry_average_summary = final_industry_df.groupby('äºŒçº§è¡Œä¸š').agg(
        å¹³å‡äº¤äº’æ”¶ç›Š=('IR', 'mean'),
        å¹³å‡ä¸»åŠ¨æƒé‡å·®=('ä¸»åŠ¨æƒé‡å·®', 'mean'),
        å¹³å‡ä¸»åŠ¨æ”¶ç›Šå·®=('ä¸»åŠ¨æ”¶ç›Šå·®', 'mean')
    ).reset_index()

    # æ³¨æ„ï¼š'æ€»è®¡ä¸»åŠ¨æƒé‡å·®'å’Œ'æ€»è®¡ä¸»åŠ¨æ”¶ç›Šå·®'é€šå¸¸ç”¨äºç´¯è®¡åˆ†æï¼Œè¿™é‡ŒæŒ‰æ—¶é—´åºåˆ—æ±‚å’Œã€‚
    # äº¤äº’æ”¶ç›ŠIRå¯ä»¥ç›´æ¥æ±‚å’Œã€‚
    output_industry_total_path = r"C:\Users\cufet\Desktop\Output_3_Industry_Total_Chart_Summary.xlsx"
    industry_average_summary.to_excel(output_industry_total_path, index=False)
    print(f"âœ… 3. è¡Œä¸šæ€»è®¡å›¾è¡¨æ•°æ®ï¼ˆæ€»è®¡ IR, ä¸»åŠ¨å·®é¢ï¼‰å·²ä¿å­˜è‡³: {output_industry_total_path}")


else:
    print("\nâŒ æ— æ³•è¾“å‡ºè¡Œä¸šçº§åˆ«æ•°æ®ï¼Œå› ä¸ºæ²¡æœ‰æœ‰æ•ˆæ•°æ®è¢«å¤„ç†ã€‚è¯·æ£€æŸ¥æ‚¨çš„ Excel æ–‡ä»¶ã€‚")

# æ‰“å°æœ€ç»ˆç»“æœæ¦‚è§ˆ
print("\n--- ğŸ”¥ æœ€ç»ˆè¾“å‡ºæ–‡ä»¶åˆ—è¡¨ ---")
print(f"1. å…¨å±€æ¯æ—¥ Brinson æ±‡æ€»: {output_file_path}")
print(f"2. è¡Œä¸šæ¯æ—¥å›¾è¡¨æ•°æ®: {output_chart_data_path}")
print(f"3. è¡Œä¸šæ€»è®¡å›¾è¡¨æ•°æ®: {output_industry_total_path}")
